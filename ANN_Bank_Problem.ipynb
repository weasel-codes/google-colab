{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_Bank_Problem",
      "provenance": [],
      "authorship_tag": "ABX9TyPKcXQRTWneOntaczB1jPKC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weasel-codes/google-colab/blob/udemy-dl/ANN_Bank_Problem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvKYPAjUTMcF"
      },
      "source": [
        "# **Bank Problem**\n",
        "* Bank is trying to resolve high turn rate.\n",
        "* A person may stay or leave the bank.\n",
        "* Goal is to create a judgement model that will tell the bank which customers might leave.\n",
        "\n",
        "> <i>Judgement graphic segment is very common and very frequently used. We can also use it for whether we should give loan or not etc...</i>\n",
        "\n",
        "* We will be using **tensor flow**. Keras is included in Tensor flow 2.0.3.\n",
        "* We are looking to build fully connect Neural Network without any convolutional layer.\n",
        "  * We will have an input variable consisting of some features and we will try to output a binary ouput for classification.\n",
        "  * We are trying to predict if customer will be leaving and will act to work it out.\n",
        "  * For this we will try to predict chances/probability that a customer might leave.\n",
        "\n",
        "* **ANN can be either in sequence of layers or connected graphs**. We will focus on sequence of layers right now."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ddjbd_AHZ39A"
      },
      "source": [
        "# **PART 1 : Data Preprocessing**\n",
        "* Data Pre-processing amounts to 70% of any data scientist work.\n",
        "* Steps here :\n",
        "  * Impor Libraries\n",
        "  * Dataset Import\n",
        "  * Encoding of features\n",
        "  * Split data into Test and Training set\n",
        "  * Apply Feature Scaling\n",
        "    * Need to be applied everytime we are building our ANN model.\n",
        "    * Always apply to all features irrespective of whether they have values or not.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekZmDr8xcFAK"
      },
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h1UDhz9cItW"
      },
      "source": [
        "# Import Dataset\n",
        "dataset = pd.read_csv('Churn_Modelling.csv')\n",
        "X = dataset.iloc[:, 3:-1].values #CUstomer_id, surname and Serial_number is not needed as it has no impact on output\n",
        "Y = dataset.iloc[:,-1].values #Last column is output"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_VPXf79hblW"
      },
      "source": [
        "#Encoding Categorical Data with Label Encoding for Gender and One hot Encoding Country \n",
        "#Lebel Encoding when there is relation btw values : male or female : gives them 0,1,2\n",
        "#One Hot Encoding when there is no relation between them : Country : Makes separate column for each with binary values\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "X[:,2] = le.fit_transform(X[:,2]) #For Gender 0 and 1\n",
        "\n",
        "ct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[1])],remainder='passthrough')\n",
        "X = np.array(ct.fit_transform(X)) # separate column for each country"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZS0aRnxfkNXP"
      },
      "source": [
        "# Split Data into Training and Test Set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1) #80:20 :: Train:Test"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DF4vXMWpk8Ny"
      },
      "source": [
        "# Feature Scaling is absolutely compulsory in DL\n",
        "# ANN is never built without it and irrespective of whether they already have some values or not, we will apply it to all columns.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hrqydo-CZ_RZ"
      },
      "source": [
        "# **PART 2 : Building ANN**\n",
        "* Initialize ANN as sequence of Layers\n",
        "* Add Input Layer and first Hidden Layer\n",
        "  * Inputlayer is to be created\n",
        "  * We need to mention no. of neurons we need on that layer\n",
        "  * No hard and fast rule on what nos we want\n",
        "* Add second Hidden Layer\n",
        "* Add Ouput Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRlbRYjxolia"
      },
      "source": [
        "#Create Variable which is ANN itself : We create sequence of layers from input to fully connected layers to output layer\n",
        "ann = tf.keras.models.Sequential()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWqHj4dPrRj-"
      },
      "source": [
        "#Add Input Layer using Dense module and mention no. of neurons needed\n",
        "# We just built a Shallow NN\n",
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVkGMwSgtJO5"
      },
      "source": [
        "#Add Hidden Layer similarly\n",
        "#6 are just a number that we took. Can we whatever gives you accuracy\n",
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_II84fyteMS"
      },
      "source": [
        "#Addition of output layer\n",
        "#We need to do something different\n",
        "#Dimension is 1 as we all need 1 or 0 as output after classification\n",
        "# Use Softmax when multiple classification outputs expected\n",
        "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid')) #probability of getting 1"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydZyvXTmaEZh"
      },
      "source": [
        "# **PART 3 : Training the ANN**\n",
        "* Optimizer adam is a Stochaistic Gradient Descent type of optimizer for eight computation and updation. \n",
        "* loss = type of data we want... binary crossentropy for binary output when two type of outputs are expected. This can also be category crossentropy. And activation is not sigmoid but softmax.\n",
        "* metrics = evaluation based on accuracy or something else"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tklAwUpgA6-r"
      },
      "source": [
        "#Compile ANN\n",
        "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "#Train ANN with default 32 batch size and epochs are repetition\n",
        "ann.fit(X_train, Y_train, batch_size=32, epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAvpCIjwaFeh"
      },
      "source": [
        "# **PART 4 : Making Prediction and Evaluating Result**\n",
        "* Predicting Test Result\n",
        "* Making Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eN56kiI5SqQ-",
        "outputId": "2e3b7254-6caa-4cd0-e8ec-d5168f7d0d48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Y_pred = ann.predict(X_test)\n",
        "Y_pred = (Y_pred>0.5) #since we are working on probability\n",
        "np.concatenate((Y_pred.reshape(len(Y_pred),1), np.array(Y_test).reshape(len(np.array(Y_test)),1)),1)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0],\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       ...,\n",
              "       [0, 0],\n",
              "       [0, 0],\n",
              "       [1, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGvNbTnZNVyt",
        "outputId": "456c8779-c5cf-466d-9166-7ba33a33903c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "Y_true = np.array(Y_test)\n",
        "cm = confusion_matrix(Y_true, Y_pred) ##correct bought, incorrect bought, corerct not bought, incorrect not bought\n",
        "accuracy_score(Y_true, Y_pred)\n",
        "print(cm)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1528   57]\n",
            " [ 220  195]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}