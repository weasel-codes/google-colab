{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_Bank_Problem",
      "provenance": [],
      "authorship_tag": "ABX9TyPYOXqE0eFbSFzJJBxKDArj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weasel-codes/google-colab/blob/udemy-dl/ANN_Bank_Problem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvKYPAjUTMcF"
      },
      "source": [
        "# **Bank Problem**\n",
        "* Bank is trying to resolve high turn rate.\n",
        "* A person may stay or leave the bank.\n",
        "* Goal is to create a judgement model that will tell the bank which customers might leave.\n",
        "\n",
        "> <i>Judgement graphic segment is very common and very frequently used. We can also use it for whether we should give loan or not etc...</i>\n",
        "\n",
        "* We will be using **tensor flow**. Keras is included in Tensor flow 2.0.3.\n",
        "* We are looking to build fully connect Neural Network without any convolutional layer.\n",
        "  * We will have an input variable consisting of some features and we will try to output a binary ouput for classification.\n",
        "  * We are trying to predict if customer will be leaving and will act to work it out.\n",
        "  * For this we will try to predict chances/probability that a customer might leave.\n",
        "\n",
        "* **ANN can be either in sequence of layers or connected graphs**. We will focus on sequence of layers right now."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ddjbd_AHZ39A"
      },
      "source": [
        "# **PART 1 : Data Preprocessing**\n",
        "* Data Pre-processing amounts to 70% of any data scientist work.\n",
        "* Steps here :\n",
        "  * Impor Libraries\n",
        "  * Dataset Import\n",
        "  * Encoding of features\n",
        "  * Split data into Test and Training set\n",
        "  * Apply Feature Scaling\n",
        "    * Need to be applied everytime we are building our ANN model.\n",
        "    * Always apply to all features irrespective of whether they have values or not.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekZmDr8xcFAK"
      },
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h1UDhz9cItW"
      },
      "source": [
        "# Import Dataset\n",
        "dataset = pd.read_csv('Churn_Modelling.csv')\n",
        "X = dataset.iloc[:, 3:-1].values #CUstomer_id, surname and Serial_number is not needed as it has no impact on output\n",
        "Y = dataset.iloc[:,-1].values #Last column is output"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_VPXf79hblW"
      },
      "source": [
        "#Encoding Categorical Data with Label Encoding for Gender and One hot Encoding Country \n",
        "#Lebel Encoding when there is relation btw values : male or female : gives them 0,1,2\n",
        "#One Hot Encoding when there is no relation between them : Country : Makes separate column for each with binary values\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "X[:,2] = le.fit_transform(X[:,2]) #For Gender 0 and 1\n",
        "\n",
        "ct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[1])],remainder='passthrough')\n",
        "X = np.array(ct.fit_transform(X)) # separate column for each country"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZS0aRnxfkNXP"
      },
      "source": [
        "# Split Data into Training and Test Set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1) #80:20 :: Train:Test"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DF4vXMWpk8Ny"
      },
      "source": [
        "# Feature Scaling is absolutely compulsory in DL\n",
        "# ANN is never built without it and irrespective of whether they already have some values or not, we will apply it to all columns.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hrqydo-CZ_RZ"
      },
      "source": [
        "# **PART 2 : Building ANN**\n",
        "* Initialize ANN as sequence of Layers\n",
        "* Add Input Layer and first Hidden Layer\n",
        "  * Inputlayer is to be created\n",
        "  * We need to mention no. of neurons we need on that layer\n",
        "  * No hard and fast rule on what nos we want\n",
        "* Add second Hidden Layer\n",
        "* Add Ouput Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRlbRYjxolia"
      },
      "source": [
        "#Create Variable which is ANN itself : We create sequence of layers from input to fully connected layers to output layer\n",
        "ann = tf.keras.models.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWqHj4dPrRj-"
      },
      "source": [
        "#Add Input Layer using Dense module and mention no. of neurons needed\n",
        "# We just built a Shallow NN\n",
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVkGMwSgtJO5"
      },
      "source": [
        "#Add Hidden Layer similarly\n",
        "#6 are just a number that we took. Can we whatever gives you accuracy\n",
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_II84fyteMS"
      },
      "source": [
        "#Addition of output layer\n",
        "#We need to do something different\n",
        "#Dimension is 1 as we all need 1 or 0 as output after classification\n",
        "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid')) #probability of getting 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydZyvXTmaEZh"
      },
      "source": [
        "# **PART 3 : Training the ANN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAvpCIjwaFeh"
      },
      "source": [
        "# **PART 4 : Making Prediction and Evaluating Result**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eN56kiI5SqQ-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}