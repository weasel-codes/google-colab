{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralNetworkMNIST.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPyzQp0kTkHmSnHRo/6dBLg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weasel-codes/google-colab/blob/udemy-dl/NeuralNetworkMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvn7QUbQ-ZuP"
      },
      "source": [
        "Assignment 3 Submission\n",
        "\n",
        "Submission By : Nitin Sharma\n",
        "\n",
        "Roll No : 202IT017"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHTlc4QW-wKt"
      },
      "source": [
        "# Required Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvIj6_9S-ymo"
      },
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Activation\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qthO4mIPMnAc"
      },
      "source": [
        "# Load Inbuilt Dataset from Keras\n",
        "\n",
        "* This MNIST dataset contains a collection of handwritten numerical digits (0-9) as 28x28-sized greyscale images. \n",
        "* These images have been size-normalized and centered in a fixed-size image. \n",
        "* It provides a total 70,000 examples, divided into a test set of 10,000 images and a training set of 60,000 images.\n",
        "* We will carve out a validation set of 10,000 images from the MNIST training set, and use the remaining 50,000 examples for training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dh16gp_JDZB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "214b900d-8e58-4cd7-81fd-995dbc5a3789"
      },
      "source": [
        "(X_Train,Y_Train),(X_Test,Y_Test)=mnist.load_data()\n",
        "print(\"Train Data : \\t\", X_Train.shape)\n",
        "print(\"Test Data : \\t\", Y_Train.shape)\n",
        "print(\"Train Output : \\t\", X_Test.shape)\n",
        "print(\"Test Output : \\t\", Y_Test.shape)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Data : \t (60000, 28, 28)\n",
            "Test Data : \t (60000,)\n",
            "Train Output : \t (10000, 28, 28)\n",
            "Test Output : \t (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVxOJSRJNVc6"
      },
      "source": [
        "# Visualize Data\n",
        "* Numerical digits (0-9) as 28x28-sized greyscale images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "Np3roMaFNXm5",
        "outputId": "053fd4ba-a202-4d44-e73f-f9e9d9c65b7f"
      },
      "source": [
        "print(\"Output Value : \", Y_Train[0])\n",
        "f, axarr = plt.subplots(2,2)\n",
        "axarr[0,0].imshow(X_Train[0],cmap='gray')\n",
        "axarr[0,1].imshow(X_Train[1],cmap='gray')\n",
        "axarr[1,0].imshow(X_Train[2],cmap='gray')\n",
        "axarr[1,1].imshow(X_Train[3],cmap='gray')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output Value :  5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vV2znRxYCrec"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ux07kTK5RXFV"
      },
      "source": [
        "## Creating categorical training Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfzXcQl8RdhB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "359dc16d-f980-45c8-cc09-4fb032be50c7"
      },
      "source": [
        "print(\"Y-Value before categorizing : \", Y_Train[0])\n",
        "Y_Train=np_utils.to_categorical(Y_Train)\n",
        "Y_Test=np_utils.to_categorical(Y_Test)\n",
        "print(\"Y-Value after categorizing : \", Y_Train[0])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Y-Value before categorizing :  5\n",
            "Y-Value after categorizing :  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZwN1rUBRiI2"
      },
      "source": [
        "## Normalizaing Gray scale value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2LnQqmORwdG",
        "outputId": "dd3d7c40-9750-490e-c5ff-19be0147c677"
      },
      "source": [
        "X_Train=X_Train/255\n",
        "X_Test=X_Test/255\n",
        "print(X_Train[5,15:20,15:20])\n",
        "\n",
        "print(\"After PreProcessing Train Data : \\t\", X_Train.shape)\n",
        "print(\"After PreProcessing Test Data : \\t\", Y_Train.shape)\n",
        "print(\"After PreProcessing Train Output : \\t\", X_Test.shape)\n",
        "print(\"After PreProcessing Test Output : \\t\", Y_Test.shape)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.94901961 0.98823529 0.98823529 0.90588235 0.45882353]\n",
            " [0.81568627 0.98823529 0.98823529 0.98823529 0.98823529]\n",
            " [0.99215686 0.96862745 0.50588235 0.67843137 0.98823529]\n",
            " [0.84705882 0.25490196 0.         0.05490196 0.28235294]\n",
            " [0.11372549 0.         0.         0.         0.        ]]\n",
            "After PreProcessing Train Data : \t (60000, 28, 28)\n",
            "After PreProcessing Test Data : \t (60000, 10)\n",
            "After PreProcessing Train Output : \t (10000, 28, 28)\n",
            "After PreProcessing Test Output : \t (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Nvr-dzXPTRV"
      },
      "source": [
        "# TASK 0 : Create basic Neural Network\n",
        "\n",
        "* We will be creating a Sequential model. What this means is that we need to create layers of NN sequentially.\n",
        "* Dense network here defines that every single node of previous layer will have a weighted link to every other node of current layer.\n",
        "* NN structure :\n",
        "  * We are creating a input layer of 28x28=784 input nodes.\n",
        "  * Each hidden layer is having 100 nodes.\n",
        "  * We have an output layer consisting of 10 nodes where each node represents digit 0-9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHHLDKlgdRUW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b335ccba-829e-4fc0-c1f6-af1c3d1ab41f"
      },
      "source": [
        "# Define model architecture\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Flatten(input_shape=(28,28)))\n",
        "model.add(Dense(100,activation='relu'))\n",
        "model.add(Dense(100,activation='relu'))\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "sgd1 = SGD(lr=0.1) # Sets learning rate. \n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=sgd1,\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "# Fit model on training data\n",
        "h1=model.fit(X_Train, Y_Train, batch_size=32, epochs=3, verbose=1, validation_split=.1)\n",
        " \n",
        "# Evaluate model on test data.\n",
        "score = model.evaluate(X_Test, Y_Test, verbose=0)\n",
        "# This returns only a score, so you will need to use another function for \n",
        "# extracting predicted labels for your confusion matrix. Use this line for that:\n",
        "#classes = model.predict_classes(X_test, batch_size=32)\n",
        "print(h1.history['accuracy'])\n",
        "print(h1.history.keys())\n",
        "print(h1.history['val_accuracy'])\n",
        "print('Validation score:', score[0])\n",
        "print('Validation accuracy:', score[1])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1688/1688 [==============================] - 3s 2ms/step - loss: 0.2964 - accuracy: 0.9098 - val_loss: 0.1355 - val_accuracy: 0.9612\n",
            "Epoch 2/3\n",
            "1688/1688 [==============================] - 3s 2ms/step - loss: 0.1292 - accuracy: 0.9610 - val_loss: 0.0971 - val_accuracy: 0.9702\n",
            "Epoch 3/3\n",
            "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0918 - accuracy: 0.9716 - val_loss: 0.0793 - val_accuracy: 0.9758\n",
            "[0.9098148345947266, 0.9609814882278442, 0.9716110825538635]\n",
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n",
            "[0.9611666798591614, 0.9701666831970215, 0.9758333563804626]\n",
            "Validation score: 0.08929310739040375\n",
            "Validation accuracy: 0.9714999794960022\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKxjbyicKKCT",
        "outputId": "2ef1e94d-fa2d-4f46-e8e6-d5b24fabfa99"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_2 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 89,610\n",
            "Trainable params: 89,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pWFVwk4Fsdi"
      },
      "source": [
        "# TASK 1 : Experiment with Batch-Size, Learning Rate and Hidden Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9rpDGL6F188"
      },
      "source": [
        "# Training the ANN on the Training set\n",
        "batches = [1, 2, 4, 6, 16, 32, 64]\n",
        "learning_rate = [0.01, 0.05, 0.1, 0.2, 0.4, 0.8]\n",
        "hidden_layers = [1, 2, 4, 8]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNUvjC87cWJ-"
      },
      "source": [
        "## 1.1 Experiments with batch size\n",
        "Here we are doing that  Keeping the rest of the parameter values constant (and equal to the default values), adjust the values of batch size parameter in the range of(1, 2, 4, 8, 16, 32, 64) and Finding  the performance (accuracy) of the model on the validation set and plotting a trend graph\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4n-7gbCPVqn",
        "outputId": "b2a29430-e210-4ca6-e8e1-5280e29344ff"
      },
      "source": [
        "batch_accuracy = {}\n",
        "\n",
        "for batch in batches :\n",
        "  # for batch in batches :\n",
        "  ann=Sequential()\n",
        "  ann.add(Flatten(input_shape=(28,28)))\n",
        "  ann.add(Dense(100,activation='relu'))\n",
        "  ann.add(Dense(100,activation='relu'))\n",
        "  ann.add(Dense(10,activation='softmax'))\n",
        "\n",
        "  # Compile model\n",
        "  sgd = SGD(lr=0.01)\n",
        "  ann.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "  print(\"################################\\n for Batch size = \", batch, \" and epoch = \", 10)\n",
        "  ann.fit(X_Train, Y_Train, batch_size = batch, epochs = 10)\n",
        "  batch_accuracy[batch]=max(ann.history.history['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "################################3\n",
            " for Batch size =  1  and epoch =  10\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 55s 914us/step - loss: 0.2252 - accuracy: 0.9301\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 54s 892us/step - loss: 0.1052 - accuracy: 0.9682\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 56s 927us/step - loss: 0.0772 - accuracy: 0.9756\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 56s 926us/step - loss: 0.0623 - accuracy: 0.9800\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 55s 919us/step - loss: 0.0491 - accuracy: 0.9847\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 54s 906us/step - loss: 0.0437 - accuracy: 0.9859\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 55s 920us/step - loss: 0.0372 - accuracy: 0.9883\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 56s 928us/step - loss: 0.0329 - accuracy: 0.9893\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 55s 921us/step - loss: 0.0271 - accuracy: 0.9911\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 55s 916us/step - loss: 0.0271 - accuracy: 0.9907\n",
            "################################3\n",
            " for Batch size =  2  and epoch =  10\n",
            "Epoch 1/10\n",
            "30000/30000 [==============================] - 29s 977us/step - loss: 0.2414 - accuracy: 0.9271\n",
            "Epoch 2/10\n",
            "30000/30000 [==============================] - 29s 965us/step - loss: 0.1086 - accuracy: 0.9671\n",
            "Epoch 3/10\n",
            "30000/30000 [==============================] - 29s 969us/step - loss: 0.0791 - accuracy: 0.9749\n",
            "Epoch 4/10\n",
            "30000/30000 [==============================] - 29s 964us/step - loss: 0.0602 - accuracy: 0.9809\n",
            "Epoch 5/10\n",
            "30000/30000 [==============================] - 28s 948us/step - loss: 0.0482 - accuracy: 0.9844\n",
            "Epoch 6/10\n",
            "30000/30000 [==============================] - 29s 958us/step - loss: 0.0398 - accuracy: 0.9869\n",
            "Epoch 7/10\n",
            "30000/30000 [==============================] - 29s 968us/step - loss: 0.0318 - accuracy: 0.9895\n",
            "Epoch 8/10\n",
            "30000/30000 [==============================] - 30s 990us/step - loss: 0.0257 - accuracy: 0.9914\n",
            "Epoch 9/10\n",
            "30000/30000 [==============================] - 29s 980us/step - loss: 0.0242 - accuracy: 0.9919\n",
            "Epoch 10/10\n",
            "30000/30000 [==============================] - 29s 982us/step - loss: 0.0178 - accuracy: 0.9941\n",
            "################################3\n",
            " for Batch size =  4  and epoch =  10\n",
            "Epoch 1/10\n",
            "15000/15000 [==============================] - 15s 1ms/step - loss: 0.2977 - accuracy: 0.9138\n",
            "Epoch 2/10\n",
            "15000/15000 [==============================] - 15s 1ms/step - loss: 0.1316 - accuracy: 0.9603\n",
            "Epoch 3/10\n",
            "15000/15000 [==============================] - 15s 1ms/step - loss: 0.0919 - accuracy: 0.9720\n",
            "Epoch 4/10\n",
            "15000/15000 [==============================] - 15s 1ms/step - loss: 0.0722 - accuracy: 0.9777\n",
            "Epoch 5/10\n",
            "15000/15000 [==============================] - 15s 1ms/step - loss: 0.0580 - accuracy: 0.9815\n",
            "Epoch 6/10\n",
            "15000/15000 [==============================] - 15s 1ms/step - loss: 0.0491 - accuracy: 0.9846\n",
            "Epoch 7/10\n",
            "15000/15000 [==============================] - 16s 1ms/step - loss: 0.0396 - accuracy: 0.9875\n",
            "Epoch 8/10\n",
            "15000/15000 [==============================] - 15s 1ms/step - loss: 0.0326 - accuracy: 0.9896\n",
            "Epoch 9/10\n",
            "15000/15000 [==============================] - 15s 994us/step - loss: 0.0270 - accuracy: 0.9919\n",
            "Epoch 10/10\n",
            "15000/15000 [==============================] - 15s 1ms/step - loss: 0.0228 - accuracy: 0.9934\n",
            "################################3\n",
            " for Batch size =  6  and epoch =  10\n",
            "Epoch 1/10\n",
            "10000/10000 [==============================] - 10s 1ms/step - loss: 0.3399 - accuracy: 0.9015\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 10s 1ms/step - loss: 0.1575 - accuracy: 0.9528\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 10s 1ms/step - loss: 0.1129 - accuracy: 0.9664\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 10s 1ms/step - loss: 0.0889 - accuracy: 0.9738\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 10s 1ms/step - loss: 0.0729 - accuracy: 0.9781\n",
            "Epoch 6/10\n",
            "10000/10000 [==============================] - 10s 1ms/step - loss: 0.0610 - accuracy: 0.9817\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 11s 1ms/step - loss: 0.0528 - accuracy: 0.9835\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 11s 1ms/step - loss: 0.0444 - accuracy: 0.9868\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 10s 1ms/step - loss: 0.0393 - accuracy: 0.9879\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 10s 1ms/step - loss: 0.0336 - accuracy: 0.9901\n",
            "################################3\n",
            " for Batch size =  16  and epoch =  10\n",
            "Epoch 1/10\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.4767 - accuracy: 0.8678\n",
            "Epoch 2/10\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.2354 - accuracy: 0.9320\n",
            "Epoch 3/10\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.1809 - accuracy: 0.9482\n",
            "Epoch 4/10\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.1476 - accuracy: 0.9574\n",
            "Epoch 5/10\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.1250 - accuracy: 0.9643\n",
            "Epoch 6/10\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.1087 - accuracy: 0.9687\n",
            "Epoch 7/10\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0952 - accuracy: 0.9723\n",
            "Epoch 8/10\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0843 - accuracy: 0.9758\n",
            "Epoch 9/10\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0758 - accuracy: 0.9781\n",
            "Epoch 10/10\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0684 - accuracy: 0.9801\n",
            "################################3\n",
            " for Batch size =  32  and epoch =  10\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.6438 - accuracy: 0.8288\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3012 - accuracy: 0.9130\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2519 - accuracy: 0.9266\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2192 - accuracy: 0.9366\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1948 - accuracy: 0.9431\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1749 - accuracy: 0.9493\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1595 - accuracy: 0.9536\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1456 - accuracy: 0.9578\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1341 - accuracy: 0.9613\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1244 - accuracy: 0.9645\n",
            "################################3\n",
            " for Batch size =  64  and epoch =  10\n",
            "Epoch 1/10\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.9243 - accuracy: 0.7635\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.3748 - accuracy: 0.8951\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.3108 - accuracy: 0.9123\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2759 - accuracy: 0.9213\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2508 - accuracy: 0.9284\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2310 - accuracy: 0.9342\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2150 - accuracy: 0.9391\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.2011 - accuracy: 0.9432\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.1897 - accuracy: 0.9460\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.1792 - accuracy: 0.9488\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "_2O-VewQajdO",
        "outputId": "eab49e67-faaf-4588-ceb0-aaab7e20cc68"
      },
      "source": [
        "#Printing max accuracies of all \n",
        "for key in batch_accuracy.keys() :\n",
        "  print(\"Max accuracy for \", key ,\" : \", batch_accuracy[key])\n",
        "\n",
        "plt.plot(list(batch_accuracy.keys()), list(batch_accuracy.values()))\n",
        "plt.ylabel('Accuracy Score')\n",
        "plt.xlabel('Batch Size')\n",
        "plt.title('Performance on the validation set(wrt Learning Rate)')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max accuracy for  1  :  0.9910500049591064\n",
            "Max accuracy for  2  :  0.9940833449363708\n",
            "Max accuracy for  4  :  0.9934333562850952\n",
            "Max accuracy for  6  :  0.9900500178337097\n",
            "Max accuracy for  16  :  0.9800999760627747\n",
            "Max accuracy for  32  :  0.9645333290100098\n",
            "Max accuracy for  64  :  0.9487500190734863\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmzb0sJJM3pS"
      },
      "source": [
        "Observations :\n",
        "1. With very small batch size, amount of time that our algo neds to train our model is very high. For eg : more than 55s per epoch in case of batch_size = 1\n",
        "2. In general on increasing the batch size, the Max(training accuracy) decreases after some time. Same can be seen in graph below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEihYW1gNLFh"
      },
      "source": [
        "## 1.2 Experiment with Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roRp9E-KUZ8z",
        "outputId": "393fb0dc-e501-4f59-df15-41facad489a3"
      },
      "source": [
        "learning_rate_accuracy = {}\n",
        "\n",
        "for rate in learning_rate :\n",
        "  # for batch in batches :\n",
        "  ann=Sequential()\n",
        "  ann.add(Flatten(input_shape=(28,28)))\n",
        "  ann.add(Dense(100,activation='relu'))\n",
        "  ann.add(Dense(100,activation='relu'))\n",
        "  ann.add(Dense(10,activation='softmax'))\n",
        "\n",
        "  # Compile model\n",
        "  sgd = SGD(lr=rate)\n",
        "  ann.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "  print(\"################################3\\n for Learning rate = \", rate, \" and epoch = \", 10)\n",
        "  ann.fit(X_Train, Y_Train, batch_size = 40, epochs = 10)\n",
        "  learning_rate_accuracy[rate]=max(ann.history.history['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "################################3\n",
            " for Learning rate =  0.01  and epoch =  20\n",
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.7086 - accuracy: 0.8178\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3257 - accuracy: 0.9065\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2737 - accuracy: 0.9209\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2405 - accuracy: 0.9301\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2151 - accuracy: 0.9380\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1942 - accuracy: 0.9438\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1772 - accuracy: 0.9484\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1628 - accuracy: 0.9526\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1507 - accuracy: 0.9560\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1398 - accuracy: 0.9589\n",
            "################################3\n",
            " for Learning rate =  0.05  and epoch =  20\n",
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3771 - accuracy: 0.8920\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1753 - accuracy: 0.9491\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1278 - accuracy: 0.9626\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1000 - accuracy: 0.9705\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0829 - accuracy: 0.9752\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0694 - accuracy: 0.9793\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0592 - accuracy: 0.9821\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0519 - accuracy: 0.9847\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0453 - accuracy: 0.9868\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0398 - accuracy: 0.9883\n",
            "################################3\n",
            " for Learning rate =  0.1  and epoch =  20\n",
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3035 - accuracy: 0.9106\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1314 - accuracy: 0.9604\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0931 - accuracy: 0.9721\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0742 - accuracy: 0.9771\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0602 - accuracy: 0.9817\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0500 - accuracy: 0.9844\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0433 - accuracy: 0.9865\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0352 - accuracy: 0.9894\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0306 - accuracy: 0.9905\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0247 - accuracy: 0.9923\n",
            "################################3\n",
            " for Learning rate =  0.2  and epoch =  20\n",
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2581 - accuracy: 0.9220\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1112 - accuracy: 0.9662\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0775 - accuracy: 0.9760\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0621 - accuracy: 0.9803\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0470 - accuracy: 0.9851\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0373 - accuracy: 0.9880\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0312 - accuracy: 0.9895\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0263 - accuracy: 0.9915\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0206 - accuracy: 0.9936\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0159 - accuracy: 0.9948\n",
            "################################3\n",
            " for Learning rate =  0.4  and epoch =  20\n",
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2589 - accuracy: 0.9200\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1152 - accuracy: 0.9649\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0860 - accuracy: 0.9727\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0684 - accuracy: 0.9784\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0569 - accuracy: 0.9822\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0481 - accuracy: 0.9847\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0430 - accuracy: 0.9862\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0357 - accuracy: 0.9884\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0329 - accuracy: 0.9893\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0295 - accuracy: 0.9901\n",
            "################################3\n",
            " for Learning rate =  0.8  and epoch =  20\n",
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.4128 - accuracy: 0.8763\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2063 - accuracy: 0.9420\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1748 - accuracy: 0.9515\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1547 - accuracy: 0.9569\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1446 - accuracy: 0.9602\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1369 - accuracy: 0.9631\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1379 - accuracy: 0.9627\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1357 - accuracy: 0.9643\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1203 - accuracy: 0.9682\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1222 - accuracy: 0.9690\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "KCsrzdCqbpEV",
        "outputId": "b4191fa2-93e4-4964-f50c-8b6d975843f3"
      },
      "source": [
        "# Learning Rate wise accuracies\n",
        "#Printing max accuracies of all \n",
        "for key in learning_rate_accuracy.keys() :\n",
        "  print(\"Max accuracy for \", key ,\" : \", learning_rate_accuracy[key])\n",
        "\n",
        "plt.plot(list(learning_rate_accuracy.keys()), list(learning_rate_accuracy.values()))\n",
        "plt.ylabel('Accuracy Score')\n",
        "plt.xlabel('learning_rate')\n",
        "plt.title('Performance on the validation set(wrt Learning Rate)')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max accuracy for  0.01  :  0.9589166641235352\n",
            "Max accuracy for  0.05  :  0.9883333444595337\n",
            "Max accuracy for  0.1  :  0.9922833442687988\n",
            "Max accuracy for  0.2  :  0.9947500228881836\n",
            "Max accuracy for  0.4  :  0.9901333451271057\n",
            "Max accuracy for  0.8  :  0.9690166711807251\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQmbRrw_Mpg4"
      },
      "source": [
        "### Observation\n",
        "1. Here we observed that when learning rate is 0.2 that our model shows high accuracy of 0.99.\n",
        "\n",
        "2. After 0.2 if we increase our learning rate, deviation from earlier trend is seen as accuracy starts decreasing. Same can be seen in the plot above\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us_c7q2Tb3z0"
      },
      "source": [
        "## 1.3 Experiment with number of Hidden Layers\n",
        "Here we are doing that Keeping the rest of the parameter values constant , adjust the values of no of hidden layer parameter in the range of (1,2,4,6,8) and Finding the performance (accuracy) of the model on the validation set and plotting a trend graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJdPMddFb_qr",
        "outputId": "51b25ea6-f4a2-4bd3-b777-02a2b65ff3e6"
      },
      "source": [
        "hidden_layers_accuracy = {}\n",
        "\n",
        "# for batch in batches :\n",
        "for i in hidden_layers :\n",
        "  print(\"################################\\n for hidden layers = \", i, \" and epoch = \", 10, \" and hidden layers : \" , i)\n",
        "  ann=Sequential()\n",
        "  j = 0\n",
        "  ann.add(Flatten(input_shape=(28,28)))\n",
        "  while j < i :\n",
        "    ann.add(Dense(100,activation='relu'))\n",
        "    j=j+1\n",
        "  ann.add(Dense(10,activation='softmax'))\n",
        "  ann.summary()\n",
        "\n",
        "  # Compile model\n",
        "  sgd = SGD(lr=0.01)\n",
        "  ann.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "  ann.fit(X_Train, Y_Train, batch_size = 40, epochs = 10)\n",
        "  hidden_layers_accuracy[i]=max(ann.history.history['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "################################\n",
            " for hidden layers =  1  and epoch =  10  and hidden layers :  1\n",
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_21 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_62 (Dense)             (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "dense_63 (Dense)             (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.7231 - accuracy: 0.8209\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3590 - accuracy: 0.9001\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3076 - accuracy: 0.9125\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2782 - accuracy: 0.9211\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2564 - accuracy: 0.9274\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2386 - accuracy: 0.9328\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2230 - accuracy: 0.9379\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2096 - accuracy: 0.9413\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1974 - accuracy: 0.9445\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1867 - accuracy: 0.9476\n",
            "################################\n",
            " for hidden layers =  2  and epoch =  10  and hidden layers :  2\n",
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_22 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_64 (Dense)             (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "dense_65 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_66 (Dense)             (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 89,610\n",
            "Trainable params: 89,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.7173 - accuracy: 0.8127\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3182 - accuracy: 0.9085\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2643 - accuracy: 0.9240\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2306 - accuracy: 0.9336\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2065 - accuracy: 0.9400\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1873 - accuracy: 0.9454\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1711 - accuracy: 0.9504\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1579 - accuracy: 0.9546\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1466 - accuracy: 0.9579\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1364 - accuracy: 0.9609\n",
            "################################\n",
            " for hidden layers =  4  and epoch =  10  and hidden layers :  4\n",
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_23 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_67 (Dense)             (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "dense_68 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_69 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_70 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_71 (Dense)             (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 109,810\n",
            "Trainable params: 109,810\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.8477 - accuracy: 0.7552\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2988 - accuracy: 0.9124\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2336 - accuracy: 0.9318\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1939 - accuracy: 0.9426\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1660 - accuracy: 0.9513\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1453 - accuracy: 0.9577\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1293 - accuracy: 0.9614\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1162 - accuracy: 0.9658\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1051 - accuracy: 0.9690\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0955 - accuracy: 0.9718\n",
            "################################\n",
            " for hidden layers =  8  and epoch =  10  and hidden layers :  8\n",
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_24 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_72 (Dense)             (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "dense_73 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_74 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_75 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_76 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_77 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_78 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_79 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_80 (Dense)             (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 150,210\n",
            "Trainable params: 150,210\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 1.3414 - accuracy: 0.5997\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3065 - accuracy: 0.9082\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2027 - accuracy: 0.9396\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1563 - accuracy: 0.9535\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1285 - accuracy: 0.9618\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1104 - accuracy: 0.9670\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0955 - accuracy: 0.9713\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0840 - accuracy: 0.9748\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0746 - accuracy: 0.9773\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0658 - accuracy: 0.9791\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "mf3wJfMTgRg1",
        "outputId": "1cda730d-5139-44bb-8fd2-918bdcd1c940"
      },
      "source": [
        "# No. of hidden layer wise accuracies\n",
        "#Printing max accuracies of all \n",
        "for key in hidden_layers_accuracy.keys() :\n",
        "  print(\"Max accuracy for \", key ,\" : \", hidden_layers_accuracy[key])\n",
        "\n",
        "plt.plot(list(hidden_layers_accuracy.keys()), list(hidden_layers_accuracy.values()))\n",
        "plt.ylabel('Accuracy Score')\n",
        "plt.xlabel('No. of hidden layers')\n",
        "plt.title('Performance on the validation set(wrt Learning Rate)')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max accuracy for  1  :  0.9475833177566528\n",
            "Max accuracy for  2  :  0.9608833193778992\n",
            "Max accuracy for  4  :  0.9718166589736938\n",
            "Max accuracy for  8  :  0.9790833592414856\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LF1btPzsPM-I"
      },
      "source": [
        "1. Here we observed that when number of hidden layers is 8 (total no layers is 9) that our model shows high accuracy.\n",
        "2. I once also achieved even higher accuracy but that resulted in over fitting as our model tried to mimic the result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IpDIEaQT2IQ"
      },
      "source": [
        "# Task 2 : Generate confusion Matrix out of best features\n",
        "For hyperparameters : batch size : 4, learning_rate = 0.2, no. of epochs : 10, hidden layers = 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJXWd-knUJZb",
        "outputId": "e517d85d-e8c6-4a96-d823-71e28b757a2a"
      },
      "source": [
        "print(\"For hyperparameters : batch size : 4, learning_rate = 0.2, no. of epochs : 10, hidden layers = 8\")\n",
        "ann=Sequential()\n",
        "ann.add(Flatten(input_shape=(28,28)))\n",
        "ann.add(Dense(100,activation='relu'))\n",
        "ann.add(Dense(100,activation='relu'))\n",
        "ann.add(Dense(10,activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "sgd = SGD(lr=0.2)\n",
        "ann.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "ann.fit(X_Train, Y_Train, batch_size = 40, epochs = 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For hyperparameters : batch size : 4, learning_rate = 0.2, no. of epochs : 10, hidden layers = 8\n",
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2513 - accuracy: 0.9229\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1085 - accuracy: 0.9667\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0788 - accuracy: 0.9758\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0604 - accuracy: 0.9811\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0482 - accuracy: 0.9845\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0385 - accuracy: 0.9876\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0321 - accuracy: 0.9898\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0241 - accuracy: 0.9919\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0209 - accuracy: 0.9929\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0165 - accuracy: 0.9948\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb72e9fffd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "K4EPH4DpvuGS",
        "outputId": "9e325694-223c-4a4e-d73a-9bdaa421d75f"
      },
      "source": [
        "plt.plot(ann.history.history['accuracy'])\n",
        "plt.xlabel('# epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CV2kRWffVBHi"
      },
      "source": [
        "## Testing Test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYNLcAiqVDLq",
        "outputId": "012d5f20-799f-467d-e9db-a362d3fb6349"
      },
      "source": [
        "# from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "# cm = confusion_matrix(new_test_target, new_test_data)\n",
        "# print(cm)\n",
        "# accuracy_score(new_test_target, new_test_data)\n",
        "Y_Pred = ann.predict(X_Test)\n",
        "print(Y_Test.shape)\n",
        "print(Y_Pred.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 10)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRzD-7daVN5J"
      },
      "source": [
        "3# Create Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xrVaZfkVpyz"
      },
      "source": [
        "Y_Pred = [np.argmax(i) for i in Y_Pred]\n",
        "Y_Test = [np.argmax(i) for i in Y_Test]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "SbRKbe6b0J2V",
        "outputId": "2406eaa5-1ba4-4ee0-ddf9-95fabe7fd432"
      },
      "source": [
        "cm = confusion_matrix(Y_Test, Y_Pred)\n",
        "print(\"Accuracy in Test Data : \", accuracy_score(Y_Test, Y_Pred))\n",
        "\n",
        "sns.heatmap(cm,  annot=True, fmt=\"d\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy in Test Data :  0.9785\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb73bce6780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfEBKX-6QZwK"
      },
      "source": [
        "Observation : \n",
        "Here we observed that the our test accuracy is 0.9948 and 0.975 for test data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiUAriYbQsI3"
      },
      "source": [
        "# TASK 3 : Overfitting \n",
        "Finding out by training the neural network on just the first 1000 of the 50,000 training examples, for 500 iterations. Showing down the loss and the accuracy on the training set as well as the test set for the trained network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mE7rcFPxQ0wy",
        "outputId": "ab2b4538-71b3-48e1-c81a-2ae0dd09946e"
      },
      "source": [
        "XTrain = X_Train[:1000]\n",
        "YTrain = Y_Train[:1000]\n",
        "print(\"Train samples : \", XTrain.shape[0])\n",
        "\n",
        "model_final = Sequential()\n",
        "model_final.add(Flatten(input_shape=(28,28)))\n",
        "model_final.add(Dense(32,activation='relu'))\n",
        "model_final.add(Dense(10,activation='softmax'))\n",
        "sgd_final = SGD(lr=0.4) # Sets learning rate. \n",
        "model_final.summary()\n",
        "\n",
        "model_final.compile(loss='categorical_crossentropy', optimizer=sgd_final, metrics=['accuracy']) \n",
        "history_final = model_final.fit(XTrain, YTrain, batch_size=128, epochs=500, verbose=1, validation_data=(X_Test, Y_Test))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train samples :  1000\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_3 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 25,450\n",
            "Trainable params: 25,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.9016 - accuracy: 0.3700 - val_loss: 1.4351 - val_accuracy: 0.5442\n",
            "Epoch 2/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 1.2242 - accuracy: 0.5980 - val_loss: 0.9465 - val_accuracy: 0.6894\n",
            "Epoch 3/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.6455 - accuracy: 0.8180 - val_loss: 0.6636 - val_accuracy: 0.7921\n",
            "Epoch 4/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.5429 - accuracy: 0.8340 - val_loss: 0.5826 - val_accuracy: 0.8221\n",
            "Epoch 5/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.4142 - accuracy: 0.8820 - val_loss: 0.5254 - val_accuracy: 0.8351\n",
            "Epoch 6/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.3947 - accuracy: 0.8740 - val_loss: 0.5994 - val_accuracy: 0.7965\n",
            "Epoch 7/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.3393 - accuracy: 0.8980 - val_loss: 0.4882 - val_accuracy: 0.8531\n",
            "Epoch 8/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.2882 - accuracy: 0.9190 - val_loss: 0.4896 - val_accuracy: 0.8498\n",
            "Epoch 9/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.2687 - accuracy: 0.9220 - val_loss: 0.5182 - val_accuracy: 0.8379\n",
            "Epoch 10/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.2467 - accuracy: 0.9300 - val_loss: 0.4359 - val_accuracy: 0.8661\n",
            "Epoch 11/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.2131 - accuracy: 0.9460 - val_loss: 0.4482 - val_accuracy: 0.8632\n",
            "Epoch 12/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.1984 - accuracy: 0.9470 - val_loss: 0.4852 - val_accuracy: 0.8496\n",
            "Epoch 13/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.1872 - accuracy: 0.9530 - val_loss: 0.4336 - val_accuracy: 0.8675\n",
            "Epoch 14/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.1644 - accuracy: 0.9610 - val_loss: 0.4959 - val_accuracy: 0.8481\n",
            "Epoch 15/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.1568 - accuracy: 0.9620 - val_loss: 0.4223 - val_accuracy: 0.8704\n",
            "Epoch 16/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.1387 - accuracy: 0.9680 - val_loss: 0.4553 - val_accuracy: 0.8576\n",
            "Epoch 17/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.1286 - accuracy: 0.9730 - val_loss: 0.4549 - val_accuracy: 0.8573\n",
            "Epoch 18/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.1173 - accuracy: 0.9730 - val_loss: 0.4342 - val_accuracy: 0.8680\n",
            "Epoch 19/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.1042 - accuracy: 0.9830 - val_loss: 0.4463 - val_accuracy: 0.8627\n",
            "Epoch 20/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.1032 - accuracy: 0.9800 - val_loss: 0.4828 - val_accuracy: 0.8521\n",
            "Epoch 21/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0907 - accuracy: 0.9870 - val_loss: 0.4513 - val_accuracy: 0.8632\n",
            "Epoch 22/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0813 - accuracy: 0.9930 - val_loss: 0.4419 - val_accuracy: 0.8683\n",
            "Epoch 23/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0755 - accuracy: 0.9920 - val_loss: 0.4623 - val_accuracy: 0.8648\n",
            "Epoch 24/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0689 - accuracy: 0.9950 - val_loss: 0.4517 - val_accuracy: 0.8637\n",
            "Epoch 25/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0642 - accuracy: 0.9960 - val_loss: 0.4434 - val_accuracy: 0.8695\n",
            "Epoch 26/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0602 - accuracy: 0.9940 - val_loss: 0.4606 - val_accuracy: 0.8643\n",
            "Epoch 27/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0580 - accuracy: 0.9970 - val_loss: 0.4561 - val_accuracy: 0.8676\n",
            "Epoch 28/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0520 - accuracy: 0.9980 - val_loss: 0.4489 - val_accuracy: 0.8685\n",
            "Epoch 29/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0471 - accuracy: 0.9990 - val_loss: 0.4586 - val_accuracy: 0.8668\n",
            "Epoch 30/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0465 - accuracy: 0.9980 - val_loss: 0.4527 - val_accuracy: 0.8696\n",
            "Epoch 31/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 0.4601 - val_accuracy: 0.8693\n",
            "Epoch 32/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0403 - accuracy: 0.9990 - val_loss: 0.4671 - val_accuracy: 0.8674\n",
            "Epoch 33/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0371 - accuracy: 1.0000 - val_loss: 0.4568 - val_accuracy: 0.8706\n",
            "Epoch 34/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.4712 - val_accuracy: 0.8673\n",
            "Epoch 35/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.4631 - val_accuracy: 0.8687\n",
            "Epoch 36/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.4694 - val_accuracy: 0.8703\n",
            "Epoch 37/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.4834 - val_accuracy: 0.8654\n",
            "Epoch 38/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.4732 - val_accuracy: 0.8682\n",
            "Epoch 39/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.4744 - val_accuracy: 0.8689\n",
            "Epoch 40/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 0.4760 - val_accuracy: 0.8692\n",
            "Epoch 41/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.4800 - val_accuracy: 0.8704\n",
            "Epoch 42/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.4750 - val_accuracy: 0.8717\n",
            "Epoch 43/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.4756 - val_accuracy: 0.8709\n",
            "Epoch 44/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.4808 - val_accuracy: 0.8697\n",
            "Epoch 45/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.4843 - val_accuracy: 0.8702\n",
            "Epoch 46/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.4848 - val_accuracy: 0.8703\n",
            "Epoch 47/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.4823 - val_accuracy: 0.8721\n",
            "Epoch 48/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.4950 - val_accuracy: 0.8685\n",
            "Epoch 49/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.8693\n",
            "Epoch 50/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.5016 - val_accuracy: 0.8684\n",
            "Epoch 51/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.4971 - val_accuracy: 0.8696\n",
            "Epoch 52/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.4946 - val_accuracy: 0.8703\n",
            "Epoch 53/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.4959 - val_accuracy: 0.8708\n",
            "Epoch 54/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.4982 - val_accuracy: 0.8708\n",
            "Epoch 55/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.4976 - val_accuracy: 0.8708\n",
            "Epoch 56/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.5040 - val_accuracy: 0.8692\n",
            "Epoch 57/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.5052 - val_accuracy: 0.8693\n",
            "Epoch 58/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.5023 - val_accuracy: 0.8702\n",
            "Epoch 59/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.5072 - val_accuracy: 0.8699\n",
            "Epoch 60/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.8696\n",
            "Epoch 61/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.5097 - val_accuracy: 0.8699\n",
            "Epoch 62/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.5125 - val_accuracy: 0.8693\n",
            "Epoch 63/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.5142 - val_accuracy: 0.8698\n",
            "Epoch 64/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.5126 - val_accuracy: 0.8697\n",
            "Epoch 65/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.5148 - val_accuracy: 0.8698\n",
            "Epoch 66/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.5148 - val_accuracy: 0.8700\n",
            "Epoch 67/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.5170 - val_accuracy: 0.8696\n",
            "Epoch 68/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.5140 - val_accuracy: 0.8710\n",
            "Epoch 69/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.5187 - val_accuracy: 0.8699\n",
            "Epoch 70/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.5191 - val_accuracy: 0.8695\n",
            "Epoch 71/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.5218 - val_accuracy: 0.8698\n",
            "Epoch 72/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.5228 - val_accuracy: 0.8703\n",
            "Epoch 73/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.5207 - val_accuracy: 0.8702\n",
            "Epoch 74/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.5230 - val_accuracy: 0.8705\n",
            "Epoch 75/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.5236 - val_accuracy: 0.8704\n",
            "Epoch 76/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.5267 - val_accuracy: 0.8698\n",
            "Epoch 77/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.5265 - val_accuracy: 0.8704\n",
            "Epoch 78/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.5296 - val_accuracy: 0.8702\n",
            "Epoch 79/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.5296 - val_accuracy: 0.8694\n",
            "Epoch 80/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.5319 - val_accuracy: 0.8698\n",
            "Epoch 81/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.5310 - val_accuracy: 0.8708\n",
            "Epoch 82/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.5304 - val_accuracy: 0.8704\n",
            "Epoch 83/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.5314 - val_accuracy: 0.8699\n",
            "Epoch 84/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.5344 - val_accuracy: 0.8703\n",
            "Epoch 85/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.5355 - val_accuracy: 0.8698\n",
            "Epoch 86/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.5338 - val_accuracy: 0.8704\n",
            "Epoch 87/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.5358 - val_accuracy: 0.8705\n",
            "Epoch 88/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.5386 - val_accuracy: 0.8696\n",
            "Epoch 89/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.5393 - val_accuracy: 0.8711\n",
            "Epoch 90/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.5385 - val_accuracy: 0.8701\n",
            "Epoch 91/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.5407 - val_accuracy: 0.8703\n",
            "Epoch 92/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.5409 - val_accuracy: 0.8701\n",
            "Epoch 93/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.5410 - val_accuracy: 0.8714\n",
            "Epoch 94/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.5434 - val_accuracy: 0.8699\n",
            "Epoch 95/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.5449 - val_accuracy: 0.8698\n",
            "Epoch 96/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.5452 - val_accuracy: 0.8701\n",
            "Epoch 97/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.5461 - val_accuracy: 0.8700\n",
            "Epoch 98/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.5465 - val_accuracy: 0.8702\n",
            "Epoch 99/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.5478 - val_accuracy: 0.8712\n",
            "Epoch 100/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.5485 - val_accuracy: 0.8701\n",
            "Epoch 101/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.5486 - val_accuracy: 0.8702\n",
            "Epoch 102/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.5486 - val_accuracy: 0.8705\n",
            "Epoch 103/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.5501 - val_accuracy: 0.8702\n",
            "Epoch 104/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.5510 - val_accuracy: 0.8704\n",
            "Epoch 105/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.5502 - val_accuracy: 0.8707\n",
            "Epoch 106/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.5530 - val_accuracy: 0.8699\n",
            "Epoch 107/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.5519 - val_accuracy: 0.8702\n",
            "Epoch 108/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.5529 - val_accuracy: 0.8701\n",
            "Epoch 109/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.5538 - val_accuracy: 0.8702\n",
            "Epoch 110/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.5544 - val_accuracy: 0.8704\n",
            "Epoch 111/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.5576 - val_accuracy: 0.8700\n",
            "Epoch 112/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.5570 - val_accuracy: 0.8702\n",
            "Epoch 113/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.5574 - val_accuracy: 0.8707\n",
            "Epoch 114/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.5593 - val_accuracy: 0.8706\n",
            "Epoch 115/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.5583 - val_accuracy: 0.8707\n",
            "Epoch 116/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.5592 - val_accuracy: 0.8705\n",
            "Epoch 117/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.5604 - val_accuracy: 0.8706\n",
            "Epoch 118/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.5609 - val_accuracy: 0.8705\n",
            "Epoch 119/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.5608 - val_accuracy: 0.8707\n",
            "Epoch 120/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.5615 - val_accuracy: 0.8704\n",
            "Epoch 121/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.5623 - val_accuracy: 0.8706\n",
            "Epoch 122/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.5631 - val_accuracy: 0.8708\n",
            "Epoch 123/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.5655 - val_accuracy: 0.8703\n",
            "Epoch 124/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.5650 - val_accuracy: 0.8709\n",
            "Epoch 125/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.5647 - val_accuracy: 0.8714\n",
            "Epoch 126/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.5662 - val_accuracy: 0.8709\n",
            "Epoch 127/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.5675 - val_accuracy: 0.8706\n",
            "Epoch 128/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.5673 - val_accuracy: 0.8706\n",
            "Epoch 129/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.5662 - val_accuracy: 0.8706\n",
            "Epoch 130/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.5691 - val_accuracy: 0.8708\n",
            "Epoch 131/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.5685 - val_accuracy: 0.8708\n",
            "Epoch 132/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.5687 - val_accuracy: 0.8710\n",
            "Epoch 133/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.5692 - val_accuracy: 0.8710\n",
            "Epoch 134/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.5712 - val_accuracy: 0.8710\n",
            "Epoch 135/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.5715 - val_accuracy: 0.8710\n",
            "Epoch 136/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.5725 - val_accuracy: 0.8709\n",
            "Epoch 137/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.5728 - val_accuracy: 0.8706\n",
            "Epoch 138/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.5738 - val_accuracy: 0.8710\n",
            "Epoch 139/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.5745 - val_accuracy: 0.8711\n",
            "Epoch 140/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.5754 - val_accuracy: 0.8706\n",
            "Epoch 141/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.5748 - val_accuracy: 0.8711\n",
            "Epoch 142/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.5763 - val_accuracy: 0.8708\n",
            "Epoch 143/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.5765 - val_accuracy: 0.8706\n",
            "Epoch 144/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.5766 - val_accuracy: 0.8708\n",
            "Epoch 145/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.5765 - val_accuracy: 0.8711\n",
            "Epoch 146/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.5771 - val_accuracy: 0.8707\n",
            "Epoch 147/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.5784 - val_accuracy: 0.8711\n",
            "Epoch 148/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.5788 - val_accuracy: 0.8707\n",
            "Epoch 149/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.5797 - val_accuracy: 0.8709\n",
            "Epoch 150/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.5807 - val_accuracy: 0.8707\n",
            "Epoch 151/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.5810 - val_accuracy: 0.8709\n",
            "Epoch 152/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.5806 - val_accuracy: 0.8710\n",
            "Epoch 153/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.5819 - val_accuracy: 0.8709\n",
            "Epoch 154/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.5824 - val_accuracy: 0.8710\n",
            "Epoch 155/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.5826 - val_accuracy: 0.8711\n",
            "Epoch 156/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.5825 - val_accuracy: 0.8716\n",
            "Epoch 157/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.5829 - val_accuracy: 0.8714\n",
            "Epoch 158/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.5835 - val_accuracy: 0.8712\n",
            "Epoch 159/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.5847 - val_accuracy: 0.8710\n",
            "Epoch 160/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.5847 - val_accuracy: 0.8714\n",
            "Epoch 161/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.5857 - val_accuracy: 0.8715\n",
            "Epoch 162/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.5856 - val_accuracy: 0.8713\n",
            "Epoch 163/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.5864 - val_accuracy: 0.8717\n",
            "Epoch 164/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.5872 - val_accuracy: 0.8715\n",
            "Epoch 165/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.5884 - val_accuracy: 0.8711\n",
            "Epoch 166/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.5883 - val_accuracy: 0.8714\n",
            "Epoch 167/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.5884 - val_accuracy: 0.8715\n",
            "Epoch 168/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.5892 - val_accuracy: 0.8714\n",
            "Epoch 169/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.5889 - val_accuracy: 0.8717\n",
            "Epoch 170/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.5895 - val_accuracy: 0.8715\n",
            "Epoch 171/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5908 - val_accuracy: 0.8711\n",
            "Epoch 172/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5911 - val_accuracy: 0.8713\n",
            "Epoch 173/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5918 - val_accuracy: 0.8712\n",
            "Epoch 174/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5916 - val_accuracy: 0.8714\n",
            "Epoch 175/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5923 - val_accuracy: 0.8711\n",
            "Epoch 176/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5924 - val_accuracy: 0.8714\n",
            "Epoch 177/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5932 - val_accuracy: 0.8713\n",
            "Epoch 178/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5936 - val_accuracy: 0.8715\n",
            "Epoch 179/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5938 - val_accuracy: 0.8716\n",
            "Epoch 180/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5939 - val_accuracy: 0.8717\n",
            "Epoch 181/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5946 - val_accuracy: 0.8718\n",
            "Epoch 182/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5949 - val_accuracy: 0.8713\n",
            "Epoch 183/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5959 - val_accuracy: 0.8714\n",
            "Epoch 184/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5963 - val_accuracy: 0.8717\n",
            "Epoch 185/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5969 - val_accuracy: 0.8715\n",
            "Epoch 186/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5975 - val_accuracy: 0.8712\n",
            "Epoch 187/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5973 - val_accuracy: 0.8718\n",
            "Epoch 188/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5977 - val_accuracy: 0.8715\n",
            "Epoch 189/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5982 - val_accuracy: 0.8713\n",
            "Epoch 190/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5985 - val_accuracy: 0.8718\n",
            "Epoch 191/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5989 - val_accuracy: 0.8715\n",
            "Epoch 192/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5994 - val_accuracy: 0.8716\n",
            "Epoch 193/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5994 - val_accuracy: 0.8718\n",
            "Epoch 194/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6001 - val_accuracy: 0.8719\n",
            "Epoch 195/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6008 - val_accuracy: 0.8716\n",
            "Epoch 196/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6013 - val_accuracy: 0.8716\n",
            "Epoch 197/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6016 - val_accuracy: 0.8716\n",
            "Epoch 198/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6016 - val_accuracy: 0.8720\n",
            "Epoch 199/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6024 - val_accuracy: 0.8718\n",
            "Epoch 200/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6023 - val_accuracy: 0.8717\n",
            "Epoch 201/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6028 - val_accuracy: 0.8714\n",
            "Epoch 202/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6032 - val_accuracy: 0.8719\n",
            "Epoch 203/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6038 - val_accuracy: 0.8718\n",
            "Epoch 204/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6041 - val_accuracy: 0.8720\n",
            "Epoch 205/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6043 - val_accuracy: 0.8721\n",
            "Epoch 206/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6047 - val_accuracy: 0.8715\n",
            "Epoch 207/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6047 - val_accuracy: 0.8717\n",
            "Epoch 208/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6057 - val_accuracy: 0.8716\n",
            "Epoch 209/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6062 - val_accuracy: 0.8717\n",
            "Epoch 210/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6064 - val_accuracy: 0.8719\n",
            "Epoch 211/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6067 - val_accuracy: 0.8718\n",
            "Epoch 212/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6066 - val_accuracy: 0.8719\n",
            "Epoch 213/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6072 - val_accuracy: 0.8722\n",
            "Epoch 214/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6078 - val_accuracy: 0.8722\n",
            "Epoch 215/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6083 - val_accuracy: 0.8717\n",
            "Epoch 216/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6083 - val_accuracy: 0.8718\n",
            "Epoch 217/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6089 - val_accuracy: 0.8719\n",
            "Epoch 218/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6096 - val_accuracy: 0.8717\n",
            "Epoch 219/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6102 - val_accuracy: 0.8718\n",
            "Epoch 220/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6106 - val_accuracy: 0.8716\n",
            "Epoch 221/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6107 - val_accuracy: 0.8719\n",
            "Epoch 222/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6107 - val_accuracy: 0.8719\n",
            "Epoch 223/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6112 - val_accuracy: 0.8718\n",
            "Epoch 224/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6114 - val_accuracy: 0.8718\n",
            "Epoch 225/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6118 - val_accuracy: 0.8721\n",
            "Epoch 226/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6121 - val_accuracy: 0.8720\n",
            "Epoch 227/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6117 - val_accuracy: 0.8719\n",
            "Epoch 228/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6125 - val_accuracy: 0.8720\n",
            "Epoch 229/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6130 - val_accuracy: 0.8720\n",
            "Epoch 230/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6134 - val_accuracy: 0.8720\n",
            "Epoch 231/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6136 - val_accuracy: 0.8719\n",
            "Epoch 232/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6143 - val_accuracy: 0.8719\n",
            "Epoch 233/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6145 - val_accuracy: 0.8720\n",
            "Epoch 234/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6147 - val_accuracy: 0.8720\n",
            "Epoch 235/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6155 - val_accuracy: 0.8718\n",
            "Epoch 236/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6155 - val_accuracy: 0.8718\n",
            "Epoch 237/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6155 - val_accuracy: 0.8719\n",
            "Epoch 238/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6160 - val_accuracy: 0.8718\n",
            "Epoch 239/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6160 - val_accuracy: 0.8719\n",
            "Epoch 240/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6167 - val_accuracy: 0.8719\n",
            "Epoch 241/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6171 - val_accuracy: 0.8720\n",
            "Epoch 242/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6176 - val_accuracy: 0.8718\n",
            "Epoch 243/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6184 - val_accuracy: 0.8716\n",
            "Epoch 244/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6186 - val_accuracy: 0.8718\n",
            "Epoch 245/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6190 - val_accuracy: 0.8717\n",
            "Epoch 246/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6190 - val_accuracy: 0.8720\n",
            "Epoch 247/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6192 - val_accuracy: 0.8721\n",
            "Epoch 248/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6191 - val_accuracy: 0.8720\n",
            "Epoch 249/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6192 - val_accuracy: 0.8720\n",
            "Epoch 250/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6196 - val_accuracy: 0.8719\n",
            "Epoch 251/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6203 - val_accuracy: 0.8719\n",
            "Epoch 252/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6204 - val_accuracy: 0.8718\n",
            "Epoch 253/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6208 - val_accuracy: 0.8718\n",
            "Epoch 254/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6212 - val_accuracy: 0.8718\n",
            "Epoch 255/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6211 - val_accuracy: 0.8718\n",
            "Epoch 256/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6217 - val_accuracy: 0.8717\n",
            "Epoch 257/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6223 - val_accuracy: 0.8719\n",
            "Epoch 258/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6224 - val_accuracy: 0.8719\n",
            "Epoch 259/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6226 - val_accuracy: 0.8717\n",
            "Epoch 260/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6228 - val_accuracy: 0.8718\n",
            "Epoch 261/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6231 - val_accuracy: 0.8720\n",
            "Epoch 262/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6234 - val_accuracy: 0.8720\n",
            "Epoch 263/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6237 - val_accuracy: 0.8718\n",
            "Epoch 264/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6242 - val_accuracy: 0.8720\n",
            "Epoch 265/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6245 - val_accuracy: 0.8721\n",
            "Epoch 266/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6248 - val_accuracy: 0.8720\n",
            "Epoch 267/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6252 - val_accuracy: 0.8719\n",
            "Epoch 268/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6252 - val_accuracy: 0.8722\n",
            "Epoch 269/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6257 - val_accuracy: 0.8720\n",
            "Epoch 270/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6258 - val_accuracy: 0.8718\n",
            "Epoch 271/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6263 - val_accuracy: 0.8716\n",
            "Epoch 272/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6264 - val_accuracy: 0.8719\n",
            "Epoch 273/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6270 - val_accuracy: 0.8720\n",
            "Epoch 274/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6272 - val_accuracy: 0.8720\n",
            "Epoch 275/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6279 - val_accuracy: 0.8716\n",
            "Epoch 276/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6276 - val_accuracy: 0.8721\n",
            "Epoch 277/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6281 - val_accuracy: 0.8719\n",
            "Epoch 278/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6285 - val_accuracy: 0.8717\n",
            "Epoch 279/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6287 - val_accuracy: 0.8717\n",
            "Epoch 280/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6290 - val_accuracy: 0.8717\n",
            "Epoch 281/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6291 - val_accuracy: 0.8718\n",
            "Epoch 282/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6294 - val_accuracy: 0.8717\n",
            "Epoch 283/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6296 - val_accuracy: 0.8717\n",
            "Epoch 284/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6300 - val_accuracy: 0.8716\n",
            "Epoch 285/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6300 - val_accuracy: 0.8719\n",
            "Epoch 286/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6304 - val_accuracy: 0.8719\n",
            "Epoch 287/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6309 - val_accuracy: 0.8719\n",
            "Epoch 288/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6312 - val_accuracy: 0.8719\n",
            "Epoch 289/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6314 - val_accuracy: 0.8719\n",
            "Epoch 290/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6317 - val_accuracy: 0.8719\n",
            "Epoch 291/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6315 - val_accuracy: 0.8720\n",
            "Epoch 292/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6320 - val_accuracy: 0.8719\n",
            "Epoch 293/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6325 - val_accuracy: 0.8719\n",
            "Epoch 294/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6327 - val_accuracy: 0.8719\n",
            "Epoch 295/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6328 - val_accuracy: 0.8719\n",
            "Epoch 296/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6331 - val_accuracy: 0.8719\n",
            "Epoch 297/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6333 - val_accuracy: 0.8719\n",
            "Epoch 298/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6337 - val_accuracy: 0.8721\n",
            "Epoch 299/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6340 - val_accuracy: 0.8718\n",
            "Epoch 300/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6342 - val_accuracy: 0.8719\n",
            "Epoch 301/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6345 - val_accuracy: 0.8719\n",
            "Epoch 302/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6349 - val_accuracy: 0.8718\n",
            "Epoch 303/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6352 - val_accuracy: 0.8722\n",
            "Epoch 304/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6352 - val_accuracy: 0.8718\n",
            "Epoch 305/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6354 - val_accuracy: 0.8719\n",
            "Epoch 306/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6355 - val_accuracy: 0.8721\n",
            "Epoch 307/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6360 - val_accuracy: 0.8719\n",
            "Epoch 308/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6361 - val_accuracy: 0.8720\n",
            "Epoch 309/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6363 - val_accuracy: 0.8720\n",
            "Epoch 310/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6368 - val_accuracy: 0.8718\n",
            "Epoch 311/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6371 - val_accuracy: 0.8718\n",
            "Epoch 312/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6373 - val_accuracy: 0.8720\n",
            "Epoch 313/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6378 - val_accuracy: 0.8717\n",
            "Epoch 314/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6379 - val_accuracy: 0.8717\n",
            "Epoch 315/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6380 - val_accuracy: 0.8718\n",
            "Epoch 316/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6383 - val_accuracy: 0.8719\n",
            "Epoch 317/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6382 - val_accuracy: 0.8718\n",
            "Epoch 318/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6386 - val_accuracy: 0.8717\n",
            "Epoch 319/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6388 - val_accuracy: 0.8720\n",
            "Epoch 320/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6391 - val_accuracy: 0.8720\n",
            "Epoch 321/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6394 - val_accuracy: 0.8716\n",
            "Epoch 322/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6397 - val_accuracy: 0.8717\n",
            "Epoch 323/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6398 - val_accuracy: 0.8720\n",
            "Epoch 324/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6401 - val_accuracy: 0.8716\n",
            "Epoch 325/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6405 - val_accuracy: 0.8717\n",
            "Epoch 326/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6409 - val_accuracy: 0.8714\n",
            "Epoch 327/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6410 - val_accuracy: 0.8715\n",
            "Epoch 328/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6412 - val_accuracy: 0.8716\n",
            "Epoch 329/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6414 - val_accuracy: 0.8717\n",
            "Epoch 330/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6417 - val_accuracy: 0.8717\n",
            "Epoch 331/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6420 - val_accuracy: 0.8717\n",
            "Epoch 332/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6421 - val_accuracy: 0.8719\n",
            "Epoch 333/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6425 - val_accuracy: 0.8717\n",
            "Epoch 334/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6427 - val_accuracy: 0.8716\n",
            "Epoch 335/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6429 - val_accuracy: 0.8718\n",
            "Epoch 336/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6431 - val_accuracy: 0.8719\n",
            "Epoch 337/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6433 - val_accuracy: 0.8719\n",
            "Epoch 338/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6437 - val_accuracy: 0.8719\n",
            "Epoch 339/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6440 - val_accuracy: 0.8718\n",
            "Epoch 340/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6442 - val_accuracy: 0.8716\n",
            "Epoch 341/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6444 - val_accuracy: 0.8717\n",
            "Epoch 342/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6446 - val_accuracy: 0.8717\n",
            "Epoch 343/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6448 - val_accuracy: 0.8717\n",
            "Epoch 344/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6451 - val_accuracy: 0.8717\n",
            "Epoch 345/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6452 - val_accuracy: 0.8719\n",
            "Epoch 346/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6456 - val_accuracy: 0.8718\n",
            "Epoch 347/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6458 - val_accuracy: 0.8717\n",
            "Epoch 348/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6460 - val_accuracy: 0.8718\n",
            "Epoch 349/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6462 - val_accuracy: 0.8718\n",
            "Epoch 350/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6464 - val_accuracy: 0.8717\n",
            "Epoch 351/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6466 - val_accuracy: 0.8718\n",
            "Epoch 352/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6468 - val_accuracy: 0.8718\n",
            "Epoch 353/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6470 - val_accuracy: 0.8718\n",
            "Epoch 354/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6473 - val_accuracy: 0.8718\n",
            "Epoch 355/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6476 - val_accuracy: 0.8716\n",
            "Epoch 356/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6478 - val_accuracy: 0.8717\n",
            "Epoch 357/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6480 - val_accuracy: 0.8718\n",
            "Epoch 358/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6484 - val_accuracy: 0.8716\n",
            "Epoch 359/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6484 - val_accuracy: 0.8719\n",
            "Epoch 360/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6486 - val_accuracy: 0.8719\n",
            "Epoch 361/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6488 - val_accuracy: 0.8717\n",
            "Epoch 362/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6489 - val_accuracy: 0.8718\n",
            "Epoch 363/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6491 - val_accuracy: 0.8717\n",
            "Epoch 364/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6491 - val_accuracy: 0.8718\n",
            "Epoch 365/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6495 - val_accuracy: 0.8719\n",
            "Epoch 366/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6497 - val_accuracy: 0.8718\n",
            "Epoch 367/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6501 - val_accuracy: 0.8717\n",
            "Epoch 368/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6503 - val_accuracy: 0.8717\n",
            "Epoch 369/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6505 - val_accuracy: 0.8716\n",
            "Epoch 370/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6507 - val_accuracy: 0.8716\n",
            "Epoch 371/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6509 - val_accuracy: 0.8716\n",
            "Epoch 372/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6511 - val_accuracy: 0.8717\n",
            "Epoch 373/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6513 - val_accuracy: 0.8717\n",
            "Epoch 374/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6514 - val_accuracy: 0.8717\n",
            "Epoch 375/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.6517 - val_accuracy: 0.8716\n",
            "Epoch 376/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 9.9893e-04 - accuracy: 1.0000 - val_loss: 0.6519 - val_accuracy: 0.8716\n",
            "Epoch 377/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9.9622e-04 - accuracy: 1.0000 - val_loss: 0.6521 - val_accuracy: 0.8719\n",
            "Epoch 378/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 9.9285e-04 - accuracy: 1.0000 - val_loss: 0.6524 - val_accuracy: 0.8720\n",
            "Epoch 379/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 9.8901e-04 - accuracy: 1.0000 - val_loss: 0.6525 - val_accuracy: 0.8719\n",
            "Epoch 380/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 9.8648e-04 - accuracy: 1.0000 - val_loss: 0.6527 - val_accuracy: 0.8717\n",
            "Epoch 381/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 9.8243e-04 - accuracy: 1.0000 - val_loss: 0.6530 - val_accuracy: 0.8718\n",
            "Epoch 382/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9.7977e-04 - accuracy: 1.0000 - val_loss: 0.6534 - val_accuracy: 0.8717\n",
            "Epoch 383/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 9.7563e-04 - accuracy: 1.0000 - val_loss: 0.6535 - val_accuracy: 0.8717\n",
            "Epoch 384/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 9.7311e-04 - accuracy: 1.0000 - val_loss: 0.6536 - val_accuracy: 0.8716\n",
            "Epoch 385/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 9.6959e-04 - accuracy: 1.0000 - val_loss: 0.6539 - val_accuracy: 0.8714\n",
            "Epoch 386/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 9.6705e-04 - accuracy: 1.0000 - val_loss: 0.6540 - val_accuracy: 0.8716\n",
            "Epoch 387/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 9.6437e-04 - accuracy: 1.0000 - val_loss: 0.6543 - val_accuracy: 0.8712\n",
            "Epoch 388/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9.6088e-04 - accuracy: 1.0000 - val_loss: 0.6545 - val_accuracy: 0.8715\n",
            "Epoch 389/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9.5770e-04 - accuracy: 1.0000 - val_loss: 0.6545 - val_accuracy: 0.8715\n",
            "Epoch 390/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 9.5460e-04 - accuracy: 1.0000 - val_loss: 0.6548 - val_accuracy: 0.8714\n",
            "Epoch 391/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9.5184e-04 - accuracy: 1.0000 - val_loss: 0.6550 - val_accuracy: 0.8715\n",
            "Epoch 392/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 9.4837e-04 - accuracy: 1.0000 - val_loss: 0.6552 - val_accuracy: 0.8716\n",
            "Epoch 393/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 9.4541e-04 - accuracy: 1.0000 - val_loss: 0.6555 - val_accuracy: 0.8716\n",
            "Epoch 394/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9.4253e-04 - accuracy: 1.0000 - val_loss: 0.6557 - val_accuracy: 0.8717\n",
            "Epoch 395/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 9.4044e-04 - accuracy: 1.0000 - val_loss: 0.6559 - val_accuracy: 0.8717\n",
            "Epoch 396/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 9.3612e-04 - accuracy: 1.0000 - val_loss: 0.6561 - val_accuracy: 0.8716\n",
            "Epoch 397/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9.3381e-04 - accuracy: 1.0000 - val_loss: 0.6563 - val_accuracy: 0.8717\n",
            "Epoch 398/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9.3118e-04 - accuracy: 1.0000 - val_loss: 0.6567 - val_accuracy: 0.8715\n",
            "Epoch 399/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 9.2897e-04 - accuracy: 1.0000 - val_loss: 0.6568 - val_accuracy: 0.8715\n",
            "Epoch 400/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 9.2550e-04 - accuracy: 1.0000 - val_loss: 0.6569 - val_accuracy: 0.8717\n",
            "Epoch 401/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9.2224e-04 - accuracy: 1.0000 - val_loss: 0.6570 - val_accuracy: 0.8716\n",
            "Epoch 402/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 9.1939e-04 - accuracy: 1.0000 - val_loss: 0.6573 - val_accuracy: 0.8714\n",
            "Epoch 403/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 9.1662e-04 - accuracy: 1.0000 - val_loss: 0.6574 - val_accuracy: 0.8715\n",
            "Epoch 404/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9.1453e-04 - accuracy: 1.0000 - val_loss: 0.6574 - val_accuracy: 0.8715\n",
            "Epoch 405/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 9.1218e-04 - accuracy: 1.0000 - val_loss: 0.6578 - val_accuracy: 0.8715\n",
            "Epoch 406/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9.0942e-04 - accuracy: 1.0000 - val_loss: 0.6578 - val_accuracy: 0.8715\n",
            "Epoch 407/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9.0559e-04 - accuracy: 1.0000 - val_loss: 0.6581 - val_accuracy: 0.8713\n",
            "Epoch 408/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 9.0311e-04 - accuracy: 1.0000 - val_loss: 0.6583 - val_accuracy: 0.8717\n",
            "Epoch 409/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 8.9960e-04 - accuracy: 1.0000 - val_loss: 0.6585 - val_accuracy: 0.8715\n",
            "Epoch 410/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 8.9734e-04 - accuracy: 1.0000 - val_loss: 0.6587 - val_accuracy: 0.8715\n",
            "Epoch 411/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 8.9476e-04 - accuracy: 1.0000 - val_loss: 0.6588 - val_accuracy: 0.8715\n",
            "Epoch 412/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 8.9240e-04 - accuracy: 1.0000 - val_loss: 0.6591 - val_accuracy: 0.8715\n",
            "Epoch 413/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 8.8924e-04 - accuracy: 1.0000 - val_loss: 0.6593 - val_accuracy: 0.8716\n",
            "Epoch 414/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 8.8676e-04 - accuracy: 1.0000 - val_loss: 0.6596 - val_accuracy: 0.8715\n",
            "Epoch 415/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 8.8420e-04 - accuracy: 1.0000 - val_loss: 0.6598 - val_accuracy: 0.8716\n",
            "Epoch 416/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 8.8184e-04 - accuracy: 1.0000 - val_loss: 0.6599 - val_accuracy: 0.8716\n",
            "Epoch 417/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 8.7950e-04 - accuracy: 1.0000 - val_loss: 0.6601 - val_accuracy: 0.8717\n",
            "Epoch 418/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 8.7574e-04 - accuracy: 1.0000 - val_loss: 0.6604 - val_accuracy: 0.8715\n",
            "Epoch 419/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 8.7400e-04 - accuracy: 1.0000 - val_loss: 0.6605 - val_accuracy: 0.8715\n",
            "Epoch 420/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8.7101e-04 - accuracy: 1.0000 - val_loss: 0.6607 - val_accuracy: 0.8716\n",
            "Epoch 421/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 8.6898e-04 - accuracy: 1.0000 - val_loss: 0.6610 - val_accuracy: 0.8716\n",
            "Epoch 422/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 8.6601e-04 - accuracy: 1.0000 - val_loss: 0.6611 - val_accuracy: 0.8713\n",
            "Epoch 423/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 8.6341e-04 - accuracy: 1.0000 - val_loss: 0.6612 - val_accuracy: 0.8715\n",
            "Epoch 424/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 8.6106e-04 - accuracy: 1.0000 - val_loss: 0.6614 - val_accuracy: 0.8714\n",
            "Epoch 425/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8.5861e-04 - accuracy: 1.0000 - val_loss: 0.6617 - val_accuracy: 0.8714\n",
            "Epoch 426/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8.5586e-04 - accuracy: 1.0000 - val_loss: 0.6618 - val_accuracy: 0.8714\n",
            "Epoch 427/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 8.5354e-04 - accuracy: 1.0000 - val_loss: 0.6620 - val_accuracy: 0.8714\n",
            "Epoch 428/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 8.5134e-04 - accuracy: 1.0000 - val_loss: 0.6622 - val_accuracy: 0.8716\n",
            "Epoch 429/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 8.4905e-04 - accuracy: 1.0000 - val_loss: 0.6622 - val_accuracy: 0.8715\n",
            "Epoch 430/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 8.4570e-04 - accuracy: 1.0000 - val_loss: 0.6623 - val_accuracy: 0.8717\n",
            "Epoch 431/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 8.4426e-04 - accuracy: 1.0000 - val_loss: 0.6625 - val_accuracy: 0.8717\n",
            "Epoch 432/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8.4177e-04 - accuracy: 1.0000 - val_loss: 0.6628 - val_accuracy: 0.8716\n",
            "Epoch 433/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 8.3926e-04 - accuracy: 1.0000 - val_loss: 0.6629 - val_accuracy: 0.8714\n",
            "Epoch 434/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 8.3643e-04 - accuracy: 1.0000 - val_loss: 0.6630 - val_accuracy: 0.8714\n",
            "Epoch 435/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 8.3518e-04 - accuracy: 1.0000 - val_loss: 0.6632 - val_accuracy: 0.8714\n",
            "Epoch 436/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 8.3200e-04 - accuracy: 1.0000 - val_loss: 0.6635 - val_accuracy: 0.8715\n",
            "Epoch 437/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8.2917e-04 - accuracy: 1.0000 - val_loss: 0.6637 - val_accuracy: 0.8717\n",
            "Epoch 438/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 8.2737e-04 - accuracy: 1.0000 - val_loss: 0.6640 - val_accuracy: 0.8715\n",
            "Epoch 439/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 8.2531e-04 - accuracy: 1.0000 - val_loss: 0.6642 - val_accuracy: 0.8714\n",
            "Epoch 440/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8.2212e-04 - accuracy: 1.0000 - val_loss: 0.6643 - val_accuracy: 0.8714\n",
            "Epoch 441/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8.2047e-04 - accuracy: 1.0000 - val_loss: 0.6646 - val_accuracy: 0.8714\n",
            "Epoch 442/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 8.1820e-04 - accuracy: 1.0000 - val_loss: 0.6648 - val_accuracy: 0.8716\n",
            "Epoch 443/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 8.1659e-04 - accuracy: 1.0000 - val_loss: 0.6650 - val_accuracy: 0.8714\n",
            "Epoch 444/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 8.1348e-04 - accuracy: 1.0000 - val_loss: 0.6650 - val_accuracy: 0.8714\n",
            "Epoch 445/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 8.1151e-04 - accuracy: 1.0000 - val_loss: 0.6651 - val_accuracy: 0.8715\n",
            "Epoch 446/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 8.0836e-04 - accuracy: 1.0000 - val_loss: 0.6654 - val_accuracy: 0.8716\n",
            "Epoch 447/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 8.0721e-04 - accuracy: 1.0000 - val_loss: 0.6654 - val_accuracy: 0.8714\n",
            "Epoch 448/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 8.0489e-04 - accuracy: 1.0000 - val_loss: 0.6657 - val_accuracy: 0.8715\n",
            "Epoch 449/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 8.0279e-04 - accuracy: 1.0000 - val_loss: 0.6659 - val_accuracy: 0.8715\n",
            "Epoch 450/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 8.0036e-04 - accuracy: 1.0000 - val_loss: 0.6660 - val_accuracy: 0.8715\n",
            "Epoch 451/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 7.9781e-04 - accuracy: 1.0000 - val_loss: 0.6662 - val_accuracy: 0.8715\n",
            "Epoch 452/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 7.9550e-04 - accuracy: 1.0000 - val_loss: 0.6663 - val_accuracy: 0.8715\n",
            "Epoch 453/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.9326e-04 - accuracy: 1.0000 - val_loss: 0.6665 - val_accuracy: 0.8715\n",
            "Epoch 454/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 7.9203e-04 - accuracy: 1.0000 - val_loss: 0.6666 - val_accuracy: 0.8715\n",
            "Epoch 455/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 7.8982e-04 - accuracy: 1.0000 - val_loss: 0.6668 - val_accuracy: 0.8715\n",
            "Epoch 456/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 7.8740e-04 - accuracy: 1.0000 - val_loss: 0.6670 - val_accuracy: 0.8715\n",
            "Epoch 457/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.8513e-04 - accuracy: 1.0000 - val_loss: 0.6671 - val_accuracy: 0.8715\n",
            "Epoch 458/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.8317e-04 - accuracy: 1.0000 - val_loss: 0.6671 - val_accuracy: 0.8715\n",
            "Epoch 459/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.8040e-04 - accuracy: 1.0000 - val_loss: 0.6674 - val_accuracy: 0.8715\n",
            "Epoch 460/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.7896e-04 - accuracy: 1.0000 - val_loss: 0.6674 - val_accuracy: 0.8716\n",
            "Epoch 461/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.7744e-04 - accuracy: 1.0000 - val_loss: 0.6677 - val_accuracy: 0.8715\n",
            "Epoch 462/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.7490e-04 - accuracy: 1.0000 - val_loss: 0.6679 - val_accuracy: 0.8715\n",
            "Epoch 463/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.7284e-04 - accuracy: 1.0000 - val_loss: 0.6682 - val_accuracy: 0.8715\n",
            "Epoch 464/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.7014e-04 - accuracy: 1.0000 - val_loss: 0.6684 - val_accuracy: 0.8714\n",
            "Epoch 465/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.6826e-04 - accuracy: 1.0000 - val_loss: 0.6686 - val_accuracy: 0.8715\n",
            "Epoch 466/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 7.6652e-04 - accuracy: 1.0000 - val_loss: 0.6687 - val_accuracy: 0.8715\n",
            "Epoch 467/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 7.6479e-04 - accuracy: 1.0000 - val_loss: 0.6689 - val_accuracy: 0.8715\n",
            "Epoch 468/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.6269e-04 - accuracy: 1.0000 - val_loss: 0.6690 - val_accuracy: 0.8715\n",
            "Epoch 469/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 7.6082e-04 - accuracy: 1.0000 - val_loss: 0.6690 - val_accuracy: 0.8715\n",
            "Epoch 470/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 7.5898e-04 - accuracy: 1.0000 - val_loss: 0.6694 - val_accuracy: 0.8715\n",
            "Epoch 471/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.5717e-04 - accuracy: 1.0000 - val_loss: 0.6695 - val_accuracy: 0.8715\n",
            "Epoch 472/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.5486e-04 - accuracy: 1.0000 - val_loss: 0.6697 - val_accuracy: 0.8715\n",
            "Epoch 473/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 7.5255e-04 - accuracy: 1.0000 - val_loss: 0.6698 - val_accuracy: 0.8714\n",
            "Epoch 474/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 7.5087e-04 - accuracy: 1.0000 - val_loss: 0.6701 - val_accuracy: 0.8716\n",
            "Epoch 475/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.4938e-04 - accuracy: 1.0000 - val_loss: 0.6704 - val_accuracy: 0.8715\n",
            "Epoch 476/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.4663e-04 - accuracy: 1.0000 - val_loss: 0.6705 - val_accuracy: 0.8715\n",
            "Epoch 477/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.4461e-04 - accuracy: 1.0000 - val_loss: 0.6706 - val_accuracy: 0.8715\n",
            "Epoch 478/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.4333e-04 - accuracy: 1.0000 - val_loss: 0.6707 - val_accuracy: 0.8716\n",
            "Epoch 479/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.4145e-04 - accuracy: 1.0000 - val_loss: 0.6709 - val_accuracy: 0.8716\n",
            "Epoch 480/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.3950e-04 - accuracy: 1.0000 - val_loss: 0.6709 - val_accuracy: 0.8715\n",
            "Epoch 481/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.3719e-04 - accuracy: 1.0000 - val_loss: 0.6711 - val_accuracy: 0.8715\n",
            "Epoch 482/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 7.3564e-04 - accuracy: 1.0000 - val_loss: 0.6713 - val_accuracy: 0.8715\n",
            "Epoch 483/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.3428e-04 - accuracy: 1.0000 - val_loss: 0.6715 - val_accuracy: 0.8715\n",
            "Epoch 484/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 7.3164e-04 - accuracy: 1.0000 - val_loss: 0.6717 - val_accuracy: 0.8716\n",
            "Epoch 485/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.3011e-04 - accuracy: 1.0000 - val_loss: 0.6718 - val_accuracy: 0.8716\n",
            "Epoch 486/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.2821e-04 - accuracy: 1.0000 - val_loss: 0.6720 - val_accuracy: 0.8716\n",
            "Epoch 487/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7.2612e-04 - accuracy: 1.0000 - val_loss: 0.6721 - val_accuracy: 0.8717\n",
            "Epoch 488/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.2434e-04 - accuracy: 1.0000 - val_loss: 0.6723 - val_accuracy: 0.8716\n",
            "Epoch 489/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.2317e-04 - accuracy: 1.0000 - val_loss: 0.6724 - val_accuracy: 0.8716\n",
            "Epoch 490/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.2126e-04 - accuracy: 1.0000 - val_loss: 0.6725 - val_accuracy: 0.8716\n",
            "Epoch 491/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 7.1914e-04 - accuracy: 1.0000 - val_loss: 0.6727 - val_accuracy: 0.8716\n",
            "Epoch 492/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.1709e-04 - accuracy: 1.0000 - val_loss: 0.6727 - val_accuracy: 0.8716\n",
            "Epoch 493/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 7.1555e-04 - accuracy: 1.0000 - val_loss: 0.6729 - val_accuracy: 0.8716\n",
            "Epoch 494/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 7.1389e-04 - accuracy: 1.0000 - val_loss: 0.6731 - val_accuracy: 0.8716\n",
            "Epoch 495/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 7.1207e-04 - accuracy: 1.0000 - val_loss: 0.6732 - val_accuracy: 0.8716\n",
            "Epoch 496/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.1025e-04 - accuracy: 1.0000 - val_loss: 0.6736 - val_accuracy: 0.8716\n",
            "Epoch 497/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 7.0844e-04 - accuracy: 1.0000 - val_loss: 0.6737 - val_accuracy: 0.8714\n",
            "Epoch 498/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.0718e-04 - accuracy: 1.0000 - val_loss: 0.6739 - val_accuracy: 0.8716\n",
            "Epoch 499/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.0540e-04 - accuracy: 1.0000 - val_loss: 0.6740 - val_accuracy: 0.8716\n",
            "Epoch 500/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 7.0350e-04 - accuracy: 1.0000 - val_loss: 0.6742 - val_accuracy: 0.8716\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-7b3cfd880c14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mhistory_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_Test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_Test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mmodel_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'test loss: {loss:.3}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'test accuracy: {accuracy:.3}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fgMOENCVDz3",
        "outputId": "4ac2a8f2-9086-4a65-fed0-7beed91639e9"
      },
      "source": [
        "loss, accuracy  = model_final.evaluate(X_Test, Y_Test, verbose=False)\n",
        "print(f'test loss: {loss:.3}')\n",
        "print(f'test accuracy: {accuracy:.3}')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test loss: 0.674\n",
            "test accuracy: 0.872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nS56Ov_dQ73Y"
      },
      "source": [
        "## Training and Testing accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "s6AAZ3wjQ-C5",
        "outputId": "bc75d484-a12f-42f9-a508-55b54c59ecee"
      },
      "source": [
        "plt.plot(history_final.history['accuracy'])\n",
        "plt.plot(history_final.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training', 'testing'], loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5xdZX3v8c9378xkciMJmQCSQBIwImgtSERS4AhibEDESyk3b1hLLJWKPdQKp4pKT1t76lHBooJKtWrl5i1i5BIMelDQTEJAwi2BApmEkBhymyRz3b/zx1p7smeyk+wks7Izs77v12tes9f990x21m89z7PWsxQRmJlZfhXqHYCZmdWXE4GZWc45EZiZ5ZwTgZlZzjkRmJnlnBOBmVnOORFYrkj6lqT/XeO6z0l6S9YxmdWbE4GZWc45EZgNQpKG1TsGGzqcCOyAkzbJfFzSo5K2SPqmpEMl/VzSZknzJY2vWP9cSUslbZB0v6RjK5adIGlxut2tQFO/Y50jaUm67W8kva7GGN8m6WFJmyStkPSZfstPTfe3IV1+STp/hKT/K+l5SRslPZDOO11Sa5W/w1vSz5+RdIek70raBFwi6SRJD6bHeFHSv0tqrNj+NZLulfSypJck/S9Jh0naKmlCxXqvl7RWUkMtZbehx4nADlR/BswCXgW8Hfg58L+AiSTf248CSHoV8H3gY+myecBPJTWmJ8UfA98BDgZuT/dLuu0JwM3Ah4EJwI3AXEnDa4hvC/B+YBzwNuAySe9M9zsljffLaUzHA0vS7T4PnAj8SRrT3wOlGv8m7wDuSI/5PaAH+FugGZgJnAn8dRrDGGA+cBdwOPBK4L6IWA3cD5xfsd/3AbdERFeNcdgQ40RgB6ovR8RLEbES+H/AbyPi4YhoB34EnJCudwHws4i4Nz2RfR4YQXKiPRloAL4UEV0RcQewsOIYc4AbI+K3EdETEd8GOtLtdiki7o+I30dEKSIeJUlGb0oXXwzMj4jvp8ddFxFLJBWAvwCuiIiV6TF/ExEdNf5NHoyIH6fH3BYRiyLioYjojojnSBJZOYZzgNUR8X8joj0iNkfEb9Nl3wbeCyCpCFxEkiwtp5wI7ED1UsXnbVWmR6efDweeLy+IiBKwApiULlsZfUdWfL7i8xTgyrRpZYOkDcAR6Xa7JOmNkhakTSobgb8iuTIn3cczVTZrJmmaqrasFiv6xfAqSXdKWp02F/1zDTEA/AQ4TtI0klrXxoj43V7GZEOAE4ENdqtITugASBLJSXAl8CIwKZ1XdmTF5xXAP0XEuIqfkRHx/RqO+1/AXOCIiBgLfA0oH2cFcHSVbf4AtO9k2RZgZEU5iiTNSpX6DxX8VeBJYHpEHETSdFYZw1HVAk9rVbeR1Areh2sDuedEYIPdbcDbJJ2ZdnZeSdK88xvgQaAb+KikBknvBk6q2PbrwF+lV/eSNCrtBB5Tw3HHAC9HRLukk0iag8q+B7xF0vmShkmaIOn4tLZyM/AFSYdLKkqamfZJPA00pcdvAD4J7K6vYgywCWiT9GrgsopldwKvkPQxScMljZH0xorl/wlcApyLE0HuORHYoBYRT5Fc2X6Z5Ir77cDbI6IzIjqBd5Oc8F4m6U/4YcW2LcClwL8D64Hl6bq1+GvgWkmbgWtIElJ5vy8AZ5MkpZdJOor/OF38d8DvSfoqXgb+FShExMZ0n98gqc1sAfrcRVTF35EkoM0kSe3Wihg2kzT7vB1YDSwDzqhY/muSTurFEVHZXGY5JL+YxiyfJP0C+K+I+Ea9Y7H6ciIwyyFJbwDuJenj2FzveKy+3DRkljOSvk3yjMHHnAQMXCMwM8s91wjMzHJu0A1c1dzcHFOnTq13GGZmg8qiRYv+EBH9n00BBmEimDp1Ki0tLfUOw8xsUJG009uE3TRkZpZzTgRmZjnnRGBmlnNOBGZmOedEYGaWc5klAkk3S1oj6bGdLJek6yUtV/JKwtdnFYuZme1cljWCbwGzd7H8LGB6+jOHZGx1MzPbzzJ7jiAifiVp6i5WeQfwn+nbox6SNE7SKyLixaxi2lc9pWD1pnbmP/4SbR3ddHT11DskM8uRM489lD8+YtyA77eeD5RNou+r91rTeTskAklzSGoNHHnkkf0XZ27Vhm08tXoz/zzvCZataesX234Px8xy6pCDmoZcIqhZRNwE3AQwY8aM/TZK3stbOvn2b57jy79YRilg0rgRvH/mFI5qHsXMo5s55rBaXmRlZnZgq2ciWEnybtmyyem8A8YnfvAo9z7+EqOHD+PoQ0bzT+98La+dNLbeYZmZDah6JoK5wOWSbgHeCGw8kPoHtnX2MP+Jl2gsFpj/P9/EYWOb6h2SmVkmMksEkr4PnA40S2oFPg00AETE14B5JO91XQ5sBT6YVSx7qqcUzPv9i0TANy+Z4SRgZkNalncNXbSb5QF8JKvj74tvPvAs/zzvSQDeOG1CnaMxM8uWnyyu4u6lLwFw2vRmGof5T2RmQ5vPcv1EBCvXb+PEKeO54T1+2NnMhj4ngn6uvP0RVm9q5y3HHspBTQ31DsfMLHNOBBU2tXdx56Mv8spDRnPRSUfsfgMzsyHAiaDCXY+tprO7xL+d9zrGjWysdzhmZvuFE0Fqa2c33/r1c0yZMJLjM3iE28zsQOVEkLruvmU8/uIm/vLUacgDCJlZjjgRpH69/A+8Yep43jdzar1DMTPbr5wISDqJH1+1iZlHN9c7FDOz/c6JALj/qbWUAk59pROBmeVP7hPBpvYuvjT/aSaOGc6JU8bXOxwzs/0u94ngp4+s4tm1W7hy1qsoFtxJbGb5k/tE0Lp+G8MK4s9n+AEyM8un3CeCleu38YpxTa4NmFluORFs2MakcSPqHYaZWd04EazfxqRxI+sdhplZ3eQ6EWzY2snqTe0cNXFUvUMxM6ubXCeChc+tB+ANUw+ucyRmZvWT60Rwz9LVNA4r8LrJY+sdiplZ3eQ2Ebywbiu3L2rlPW88kqaGYr3DMTOrm/wmgpe3AjD7NYfVORIzs/rKbSJYt6UDgOYxw+sciZlZfWWaCCTNlvSUpOWSrqqyfIqk+yQ9Kul+SZOzjKfSH9o6AWge5URgZvmWWSKQVARuAM4CjgMuknRcv9U+D/xnRLwOuBb4l6zi6W9dWwfDCuKgEcP21yHNzA5IWdYITgKWR8SzEdEJ3AK8o986xwG/SD8vqLI8M+vaOpkwutFvIzOz3MsyEUwCVlRMt6bzKj0CvDv9/C5gjKQJGcbUa92WDia4WcjMrO6dxX8HvEnSw8CbgJVAT/+VJM2R1CKpZe3atQNy4LVpjcDMLO+yTAQrgcqxnSen83pFxKqIeHdEnAD8QzpvQ/8dRcRNETEjImZMnDhxQIJb19ZB82jXCMzMskwEC4HpkqZJagQuBOZWriCpWVI5hquBmzOMp491bZ1MGOUagZlZZokgIrqBy4G7gSeA2yJiqaRrJZ2brnY68JSkp4FDgX/KKp5KWzu72dbVwwTXCMzMyPTeyYiYB8zrN++ais93AHdkGUM1t/wu6cNudh+BmVndO4v3u47uHq6983EA9xGYmZHDRLCtc/tNSb5ryMws46ahA9G2ru2JYPzIAU4EXe2wsRUmHA2dbbD6MZgyc8/2EQF78pBbqQdQss3Wl2HUhO37gT3bV6WtL4MKMGLc9nk9Xcl+iw3JdHdHsv9iI0QpjSVg2PBkvZ7OZN6mVcny0ROT/Xa3Q/smGD4aCsOSdYqN0DQ2+bsVG6FjM3Rvg442GD4GGkdDqTtd3gCdW6FxZHrcUvJ7yxoYcXASw5a10N0J46ck5ejYnGzb0ZbEN6o5OW6hmPzu7oBSF3RuARWT+Srs/GdY+t3ZtgG6tiYxFxugODzZNiKJo9rvnk7o2gZjDkvmbdsADSOSeU3j0r9vJGWKfttGqWJZKfnONY5MytXTCaMPSf6dSl3J96IwLPk3ahyVlFNK1h0xDgoNED3J37fUk5Sjc2uy/+Fjkumu9orvkbb/rjav96umGtdX9fWHNSX/Rij5rkRPUqaezqQ8xfRvH6Xt5aum/H9gp3axfJ+23c2m+3Lc8VOSf+MBlrtEsDWtEZz6ymaOOLjfKyp/diVM+RM47p3Jf+aubckJ4oWHkpPUqGZYuRjWPgHP/RqOelNysn/jHNjwAvz6enj5GTj4aNi0MvkSH3M2jDsSlt+XrDN2Mkx+Q3KiGnlw8qXv2poc5+VnkxPlK98Cbathw4rki14oJsfuaocNz8PY9K7cLWuSxDNifHIiWf8cHHVG8h9m3TPJ8ccdCR2bkv/846cm23W3J//R2zcmcZS60/98TckJk0jiIJITa08X9HQk+y1rGJnEDTBsRHLiKXUn04Vhycm0pyOjf0WznHrbF+ANHxrw3Sp2m/kOLDNmzIiWlpa93v6xlRs558sPcNP7TuStrzkMnrgzOTl/78+TE2vZWf8nOXkvu7v2nY+fCq8+B/77VzByAjy7YPuyo86AQ18Dj/8kOfkefHRyIt62HsYcmlzl9HQmV5vtG+Ggw5OTeOeW5Mp286pk2cRXQ9tLycl5zGGw9kk4aFKSCNrWJPNHTkiuEks9ydXl8IOSk/PLzyRX1sWG5Ip8xPgkwRQbk+TQ3Z5cOXZ3JGUpFGHTi8nVWbEh2VZKlpev1CO9mi42JCd/Ka05lJLkqUJyjGFNSXwjD06ON2J8UrZS9/ak27E5OUbX1u3JrXE0bF3XL8kU0lpIz/ard5Tsu31jcvxxabJc/3yyTeOopAbSODo5TsfmZH75KrOhKdnX8DHbazflq+4dfiKprUByBV/+W3d3JMmv9/9U+Sq53xVvYVhSts2rk3kjxiW1ghHjk/hLXUkZUVoDUcVnKpYpqYF0b0v+jSXYuh6Kw7bX0srJu3PL9hpA46jkexeRft82JMsaRyU/kFw8NIxK/i6wvVZS+TmgT22nz7LK31SZt7P1ga4tyfdBxeTvVK6BFRqS70FPV7KuimnNZ1d2UyPeZY35ANx24jHbv9t7SNKiiJhRbVnuagTtadPQiMa0+n7re6qv+PO/33He8LFw9Blw/HtgZUvyhWx7CZZ8D94/F6aemp6UUm1rkpN+w0g4eFoyb9Y/Jr8LueueqY9Djq13BDt38FEZ7HPgd2lDX+4SQblpaERDMW0G2Y0Zf5Fc/TZPh5MuTa7aAF711uR3qQSzrk2uevsbfciO7XlOAGZ2gMldIthWWSPYtn73G/zpPyfV050pFKonATOzQSJ3l6flpqGxG5+E1oU7rnDwUTDz8u3Tu0oCZmZDQO5qBOWmocm3vrX6Ch+8K+m8ffDfk84yM7MhLneJoPKBsqpGpvfh/9UD6T3pZmZDW/4SQdo0FKMPRW0vJTP/ZnFyi+LKxcmtdwCH/VGdIjQz27/ylwg6eyiI9AnN1EGHJ08DH3FS3eIyM6uX3HUWb+vqYWTjMFR+dB7cIWxmuZa7GsHWjm4+VfgP6NwMB02GV55Z75DMzOoqd4mg0PYiF8TPk4nXvx9O/0R9AzIzq7PcNQ0V1j+zfaI8joqZWY7lLhGM2vTf2yeGuW/AzCxXiaCju4fmzhXbZwzzG8rMzHKVCF7c0M5hqhhfyHcLmZnlKxGs2dzBQWzZPmOY+wjMzHKVCHpKwVhVJALXCMzM8pUIIsI1AjOzfjJNBJJmS3pK0nJJV1VZfqSkBZIelvSopLOzjKcn+tUInAjMzLJLBJKKwA3AWcBxwEWSjuu32ieB2yLiBOBC4CtZxQNQKgUHsXX7DD9HYGaWaY3gJGB5RDwbEZ3ALcA7+q0TwEHp57HAqgzjQV1tDFPFYHOFhiwPZ2Y2KGSZCCYBFTft05rOq/QZ4L2SWoF5wN9U25GkOZJaJLWsXbt2rwMqdmzsO6PUvdf7MjMbKurdWXwR8K2ImAycDXxH0g4xRcRNETEjImZMnDhxrw9W6NgEwNo/+jBMPS15Ib2ZWc5lmQhWAkdUTE9O51X6EHAbQEQ8CDQBmb0JvtC5GYC2yafBJXf6yWIzM7JNBAuB6ZKmSWok6Qye22+dF4AzASQdS5II9r7tZzfU05n8dgIwM+uVWSKIiG7gcuBu4AmSu4OWSrpW0rnpalcCl0p6BPg+cElERFYxlfsEVGzM7BBmZoNNpu8jiIh5JJ3AlfOuqfj8OHBKljH0UeoCQMXcvYbBzGyn6t1ZvH/1JIkAJwIzs175SgRp01DBTUNmZr1ylQjU20fgGoGZWVmuEsH2PgLXCMzMynKVCNTjGoGZWX+5SgSuEZiZ7ShXiaDcR1AY5hqBmVlZrhLB9gfKPOqomVlZrhKBepuGnAjMzMpylQh6nyMY5j4CM7OymhKBpB9Kelu1IaIHk3IfQbHgPgIzs7JaT+xfAS4Glkn6nKRjMowpMyp10RlFVFS9QzEzO2DUlAgiYn5EvAd4PfAcMF/SbyR9UNKgaXAvlLrpZhgFORGYmZXV3NQjaQJwCfCXwMPAdSSJ4d5MIstCdNNNgYLzgJlZr5oayyX9CDgG+A7w9oh4MV10q6SWrIIbaCp1002RRtcIzMx61dpren1ELKi2ICJmDGA8mSqEm4bMzPqrtWnoOEnjyhOSxkv664xiyoxK3XRRdNOQmVmFWhPBpRGxoTwREeuBS7MJKTuFUjfdUXSNwMysQq2JoChtP3tKKgKD7qkslbropojzgJnZdrX2EdxF0jF8Yzr94XTeoKLoSROBM4GZWVmtieATJCf/y9Lpe4FvZBJRhgrRTSfFeodhZnZAqSkRREQJ+Gr6M2iVHygzM7Ptah1raLqkOyQ9LunZ8k8N282W9JSk5ZKuqrL8i5KWpD9PS9pQbT8DRdFFt1wjMDOrVOvl8X8Anwa+CJwBfJDdJJG0Q/kGYBbQCiyUNDciHi+vExF/W7H+3wAn7FH0e6j8HIGZmW1X611DIyLiPkAR8XxEfAZ42262OQlYHhHPRkQncAvwjl2sfxHw/Rrj2SuFUjc97iMwM+uj1svjjnQI6mWSLgdWAqN3s80kYEXFdCvwxmorSpoCTAN+sZPlc4A5AEceeWSNIe+oED10q2mvtzczG4pqrRFcAYwEPgqcCLwX+MAAxnEhcEdE9FRbGBE3RcSMiJgxceLEvT5IIbrpydm7eMzMdme3NYK0rf+CiPg7oI2kf6AWK4EjKqYnp/OquRD4SI373WtJInAfgZlZpd1eHqdX6afuxb4XAtMlTZPUSHKyn9t/JUmvBsYDD+7FMfZIIbrp8V1DZmZ91Hp5/LCkucDtwJbyzIj44c42iIjutD/hbqAI3BwRSyVdC7RERDkpXAjcEhGxVyXYA4XocY3AzKyfWs+KTcA64M0V8wLYaSIAiIh5wLx+867pN/2ZGmPYZ4UoURrcr102MxtwtT5ZXGu/wAFN0UPJt4+amfVR6xvK/oOkBtBHRPzFgEeUoQI9rhGYmfVTa9PQnRWfm4B3AasGPpxsKUqU3FlsZtZHrU1DP6iclvR94IFMIspQIXoI1wjMzPrY27PidOCQgQxkfyhQ8u2jZmb91NpHsJm+fQSrSd5RMKgUoodwZ7GZWR+1Ng2NyTqQ/aGAm4bMzPqr9X0E75I0tmJ6nKR3ZhdWNgruLDYz20Gtl8efjoiN5YmI2EDyfoJBpUgPJQ86Z2bWR61nxWrrDa6xGkql5JcGV9hmZlmrNRG0SPqCpKPTny8Ai7IMbMCVugHcR2Bm1k+tZ8W/ATqBW0neNNbOfhg2ekClrzoI9xGYmfVR611DW4AdXj4/qJSSRODOYjOzvmq9a+heSeMqpsdLuju7sDLgpiEzs6pqPSs2p3cKARAR6xlsTxZH0lnspiEzs75qTQQlSb1vjZc0lSqjkR7QemsETgRmZpVqvZfyH4AHJP0SEHAaMCezqLJQcmexmVk1tXYW3yVpBsnJ/2Hgx8C2LAMbcL5ryMysqloHnftL4ApgMrAEOJnkZfNv3tV2BxQ3DZmZVVVrH8EVwBuA5yPiDOAEYMOuNznA9N4+6ruGzMwq1XpWbI+IdgBJwyPiSeCY7MLKQJoIKLhGYGZWqdbO4tb0OYIfA/dKWg88n11YGejtI/BYQ2ZmlWrtLH5X+vEzkhYAY4G7MosqC+UagZuGzMz62OOzYkT8MiLmRkTn7taVNFvSU5KWS6o6RIWk8yU9LmmppP/a03hqlnYWe/RRM7O+MjsrSioCNwCzgFZgoaS5EfF4xTrTgauBUyJivaTsnlaOco3AfQRmZpWybCc5CVgeEc+mtYdbgHf0W+dS4IZ0yAoiYk1m0ZQfKHNnsZlZH1kmgknAiorp1nRepVcBr5L0a0kPSZpdbUeS5khqkdSydu3avYvGTxabmVVV757TYcB04HTgIuDrlaOclkXETRExIyJmTJw4ce+OlPYR+PZRM7O+skwEK4EjKqYnp/MqtQJzI6IrIv4beJokMQw8DzFhZlZVlolgITBd0jRJjcCFwNx+6/yYpDaApGaSpqJnM4kmbRqSE4GZWR+ZJYKI6AYuB+4GngBui4ilkq6VdG662t3AOkmPAwuAj0fEukwCKg8x4aYhM7M+Mr2pPiLmAfP6zbum4nMA/zP9yZZvHzUzq6rencX7T7mz2A+UmZn1kaNEkNYIiq4RmJlVyk8i8F1DZmZV5ScReBhqM7OqcpcI5NFHzcz6yM9ZsfyqyoI7i83MKuUnEaR9BHLTkJlZH/lJBL19BK4RmJlVyl8i8F1DZmZ95CcRlG8fdY3AzKyP/CSCtLNYxfwU2cysFvk5K/bePuoagZlZpfwkglOu4Kj279JTbKp3JGZmB5TcJIIAShQoFFTvUMzMDii5SQQ9pQCgICcCM7NKuUkEaR6g6BqBmVkfOUoESSZwhcDMrK/cJII0D7hpyMysn9wkgp4o9xHUORAzswNMbhJBKdxZbGZWTW4SQZSS304EZmZ95SYRlNw0ZGZWVaaJQNJsSU9JWi7pqirLL5G0VtKS9Ocvs4qlNxE4E5iZ9ZHZwDuSisANwCygFVgoaW5EPN5v1Vsj4vKs4ijr6b191InAzKxSljWCk4DlEfFsRHQCtwDvyPB4u1S+fbToRGBm1keWiWASsKJiujWd19+fSXpU0h2Sjqi2I0lzJLVIalm7du1eBeM+AjOz6urdWfxTYGpEvA64F/h2tZUi4qaImBERMyZOnLhXByr5gTIzs6qyTAQrgcor/MnpvF4RsS4iOtLJbwAnZhVMqeQhJszMqskyESwEpkuaJqkRuBCYW7mCpFdUTJ4LPJFVMOWmIQ86Z2bWV2Z3DUVEt6TLgbuBInBzRCyVdC3QEhFzgY9KOhfoBl4GLskqHjcNmZlVl+l7GyNiHjCv37xrKj5fDVydZQxlHn3UzKy6encW7zfhsYbMzKrKTSLo8VhDZmZV5SYRbO8srnMgZmYHmNycFkseYsLMrKrcJAK/oczMrLrcJIKekoeYMDOrJjeJwMNQm5lVl+lzBAcSP1BmNrh1dXXR2tpKe3t7vUM5oDU1NTF58mQaGhpq3iY3iSA8+qjZoNba2sqYMWOYOnWqb/rYiYhg3bp1tLa2Mm3atJq3y1HTUPLbNQKzwam9vZ0JEyY4CeyCJCZMmLDHtabcJIIejz5qNug5Ceze3vyNcpMIyk1DfkOZmVlfuUkEvU1D7iQws72wYcMGvvKVr+zxdmeffTYbNmzY5TrXXHMN8+fP39vQ9lmOEoE7i81s7+0sEXR3d+9yu3nz5jFu3LhdrnPttdfylre8ZZ/i2xe5uWuox0NMmA0Zn/3pUh5ftWlA93nc4Qfx6be/ZqfLr7rqKp555hmOP/54GhoaaGpqYvz48Tz55JM8/fTTvPOd72TFihW0t7dzxRVXMGfOHACmTp1KS0sLbW1tnHXWWZx66qn85je/YdKkSfzkJz9hxIgRXHLJJZxzzjmcd955TJ06lQ984AP89Kc/pauri9tvv51Xv/rVrF27losvvphVq1Yxc+ZM7r33XhYtWkRzc/M+lz03NQL3EZjZvvjc5z7H0UcfzZIlS/i3f/s3Fi9ezHXXXcfTTz8NwM0338yiRYtoaWnh+uuvZ926dTvsY9myZXzkIx9h6dKljBs3jh/84AdVj9Xc3MzixYu57LLL+PznPw/AZz/7Wd785jezdOlSzjvvPF544YUBK1tuagQlD0NtNmTs6sp9fznppJP63Kt//fXX86Mf/QiAFStWsGzZMiZMmNBnm2nTpnH88ccDcOKJJ/Lcc89V3fe73/3u3nV++MMfAvDAAw/07n/27NmMHz9+wMqSn0TgN5SZ2QAaNWpU7+f777+f+fPn8+CDDzJy5EhOP/30qvfyDx8+vPdzsVhk27ZtVfddXq9YLO62D2Ig5KZpyA+Umdm+GDNmDJs3b666bOPGjYwfP56RI0fy5JNP8tBDDw348U855RRuu+02AO655x7Wr18/YPvOXY2gkJvUZ2YDacKECZxyyim89rWvZcSIERx66KG9y2bPns3XvvY1jj32WI455hhOPvnkAT/+pz/9aS666CK+853vMHPmTA477DDGjBkzIPtWuRN1sJgxY0a0tLTs8XZ3PrqKy//rYe792//B9EMH5o9nZvvPE088wbHHHlvvMOqmo6ODYrHIsGHDePDBB7nssstYsmRJ1XWr/a0kLYqIGdXWz1GNIPnt20fNbDB64YUXOP/88ymVSjQ2NvL1r399wPadaSKQNBu4DigC34iIz+1kvT8D7gDeEBF7frlfA48+amaD2fTp03n44Ycz2XdmLeaSisANwFnAccBFko6rst4Y4Argt1nFApVvKHMmMDOrlGXX6UnA8oh4NiI6gVuAd1RZ7x+BfwUyfdtEuWmo6CqBmVkfWSaCScCKiunWdF4vSa8HjoiIn2UYB+DnCMzMdqZuN1NKKgBfAK6sYd05kloktaxdu3avjre9j8CZwMysUpaJYCVwRMX05HRe2RjgtcD9kp4DTgbmStrh9qaIuCkiZkTEjIkTJ+5VMH6gzMz2xd4OQw3wpS99ia1bt/ZO1zI09f6UZSJYCEyXNE1SI3AhMLe8MCI2RkRzREyNiKnAQ8C5Wd01tL2zOIu9m9lQN5CJoJahqfenzG4fjYhuSZcDd5PcPnpzRCyVdC3QEhFzd72HAY8H8ItpzIaEn18Fq38/sPs87I5hU8gAAAhWSURBVI/grKp3uAN9h6GeNWsWhxxyCLfddhsdHR28613v4rOf/Sxbtmzh/PPPp7W1lZ6eHj71qU/x0ksvsWrVKs444wyam5tZsGBBTUNTL1y4kA996EMUCgVmzZrFz3/+cx577LGBLXMq0z6CiJgXEa+KiKMj4p/SeddUSwIRcXpWtQFw05CZ7ZvKYahnzZrFsmXL+N3vfseSJUtYtGgRv/rVr7jrrrs4/PDDeeSRR3jssceYPXs2H/3oRzn88MNZsGABCxYs2GG/Oxua+oMf/CA33ngjS5YsoVgsZlq2HD1Z7KYhsyFjF1fu+8M999zDPffcwwknnABAW1sby5Yt47TTTuPKK6/kE5/4BOeccw6nnXbabvdVbWjqDRs2sHnzZmbOnAnAxRdfzJ133plZeXKTCMp9BB5iwsz2VURw9dVX8+EPf3iHZYsXL2bevHl88pOf5Mwzz+Saa67Z5b5qHZo6S7kZizP8QJmZ7YPKYaj/9E//lJtvvpm2tjYAVq5cyZo1a1i1ahUjR47kve99Lx//+MdZvHjxDtvWYty4cYwZM4bf/jYZcOGWW24Z4NL0lZsagZuGzGxfVA5DfdZZZ3HxxRf3Nt2MHj2a7373uyxfvpyPf/zjFAoFGhoa+OpXvwrAnDlzmD17dm9fQS2++c1vcumll1IoFHjTm97E2LFjMytbboahvmfpan6yZBVfuOCPGT4s244XMxt4eRuGuq2tjdGjRwNJR/WLL77IddddV9O2HoZ6J976msN462sOq3cYZmY1+dnPfsa//Mu/0N3dzZQpU/jWt76V2bFykwjMzAaTCy64gAsuuGC/HCs3ncVmNvgNtqbsetibv5ETgZkNCk1NTaxbt87JYBcignXr1tHU1LRH27lpyMwGhcmTJ9Pa2srejkCcF01NTUyePHmPtnEiMLNBoaGhgWnTptU7jCHJTUNmZjnnRGBmlnNOBGZmOTfoniyWtBZ4fi83bwb+MIDhDAYucz64zPmwL2WeEhFVX/E46BLBvpDUsrNHrIcqlzkfXOZ8yKrMbhoyM8s5JwIzs5zLWyK4qd4B1IHLnA8ucz5kUuZc9RGYmdmO8lYjMDOzfpwIzMxyLjeJQNJsSU9JWi7pqnrHM1Ak3SxpjaTHKuYdLOleScvS3+PT+ZJ0ffo3eFTS6+sX+d6TdISkBZIel7RU0hXp/CFbbklNkn4n6ZG0zJ9N50+T9Nu0bLdKakznD0+nl6fLp9Yz/r0lqSjpYUl3ptNDurwAkp6T9HtJSyS1pPMy/W7nIhFIKgI3AGcBxwEXSTquvlENmG8Bs/vNuwq4LyKmA/el05CUf3r6Mwf46n6KcaB1A1dGxHHAycBH0n/PoVzuDuDNEfHHwPHAbEknA/8KfDEiXgmsBz6Urv8hYH06/4vpeoPRFcATFdNDvbxlZ0TE8RXPDGT73Y6IIf8DzATurpi+Gri63nENYPmmAo9VTD8FvCL9/ArgqfTzjcBF1dYbzD/AT4BZeSk3MBJYDLyR5CnTYen83u85cDcwM/08LF1P9Y59D8s5OT3pvRm4E9BQLm9FuZ8DmvvNy/S7nYsaATAJWFEx3ZrOG6oOjYgX08+rgUPTz0Pu75A2AZwA/JYhXu60mWQJsAa4F3gG2BAR3ekqleXqLXO6fCMwYf9GvM++BPw9UEqnJzC0y1sWwD2SFkmak87L9Lvt9xEMcRERkobkPcKSRgM/AD4WEZsk9S4biuWOiB7geEnjgB8Br65zSJmRdA6wJiIWSTq93vHsZ6dGxEpJhwD3SnqycmEW3+281AhWAkdUTE9O5w1VL0l6BUD6e006f8j8HSQ1kCSB70XED9PZQ77cABGxAVhA0jQyTlL5gq6yXL1lTpePBdbt51D3xSnAuZKeA24haR66jqFb3l4RsTL9vYYk4Z9Ext/tvCSChcD09I6DRuBCYG6dY8rSXOAD6ecPkLShl+e/P73T4GRgY0V1c9BQcun/TeCJiPhCxaIhW25JE9OaAJJGkPSJPEGSEM5LV+tf5vLf4jzgF5E2Ig8GEXF1REyOiKkk/19/ERHvYYiWt0zSKEljyp+BtwKPkfV3u94dI/uxA+Zs4GmSdtV/qHc8A1iu7wMvAl0k7YMfImkbvQ9YBswHDk7XFcndU88Avwdm1Dv+vSzzqSTtqI8CS9Kfs4dyuYHXAQ+nZX4MuCadfxTwO2A5cDswPJ3flE4vT5cfVe8y7EPZTwfuzEN50/I9kv4sLZ+rsv5ue4gJM7Ocy0vTkJmZ7YQTgZlZzjkRmJnlnBOBmVnOORGYmeWcE4HZfiTp9PJImmYHCicCM7OccyIwq0LSe9Px/5dIujEd8K1N0hfT9wHcJ2liuu7xkh5Kx4P/UcVY8a+UND99h8BiSUenux8t6Q5JT0r6nioHSTKrAycCs34kHQtcAJwSEccDPcB7gFFAS0S8Bvgl8Ol0k/8EPhERryN5urM8/3vADZG8Q+BPSJ4Ah2S01I+RvBvjKJJxdczqxqOPmu3oTOBEYGF6sT6CZJCvEnBrus53gR9KGguMi4hfpvO/DdyejhczKSJ+BBAR7QDp/n4XEa3p9BKS90k8kH2xzKpzIjDbkYBvR8TVfWZKn+q33t6Oz9JR8bkH/z+0OnPTkNmO7gPOS8eDL78vdgrJ/5fyyJcXAw9ExEZgvaTT0vnvA34ZEZuBVknvTPcxXNLI/VoKsxr5SsSsn4h4XNInSd4SVSAZ2fUjwBbgpHTZGpJ+BEiGBf5aeqJ/FvhgOv99wI2Srk338ef7sRhmNfPoo2Y1ktQWEaPrHYfZQHPTkJlZzrlGYGaWc64RmJnlnBOBmVnOORGYmeWcE4GZWc45EZiZ5dz/B0syRjlm5IuvAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rR5zT6lhVXpL"
      },
      "source": [
        "OBSERVATION : \n",
        "* Here overfitting problem occurs as we can see that as our no. of interation increasaes, training accuracy is increased up to 1.\n",
        "* It means that our model extremly learn from train data but when comes to test accuracy it almost saturated at 0.87.\n",
        "* It means that our model doesn't fit WELL for new data therefore here comes the generlisation error and model is not suited for predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoBb-0_AVwLk"
      },
      "source": [
        "# TASK 4 : "
      ]
    }
  ]
}